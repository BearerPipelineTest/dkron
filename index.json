[
{
	"uri": "/basics/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Running the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin.\nRun Dkron with default setting: dkron agent --server --bootstrap-expect=1\nNavigate to http://localhost:8080\nInstalling the package Debian repo APT repository:\ndeb [trusted=yes] https://repo.distrib.works/apt/ / Then install: sudo apt-get install dkron\nYUM repo YUM repository:\n[dkron] name=Dkron Pro Private Repo baseurl=https://repo.distrib.works/yum/ enabled=1 gpgcheck=0 Then install: sudo yum install dkron\nThis will start Dkron as a system service and the place example configuration file under /etc/dkron/dkron.yml\nRunning in Docker Dkron provides an official Docker image vi Dockerhub that can be used for deployment on any system running Docker.\nLaunching Dkron as a new container Here’s a quick one-liner to get you off the ground (please note, we recommend further configuration for production deployments below):\ndocker run -d -p 8080:8080 --name dkron dkron/dkron agent --server --bootstrap-expect=1 --node-name=node1 This will launch a Dkron server on port 8080 by default. You can use docker logs -f dkron to follow the rest of the initialization progress. Once the Dkron startup completes you can access the app at localhost:8080\nSince Docker containers have their own ports and we just map them to the system ports as needed it’s easy to move Dkron onto a different system port if you wish. For example running Dkron on port 12345:\ndocker run -d -p 12345:8080 --name dkron dkron/dkron agent --server --bootstrap-expect=1 --node-name=node1 Mounting a mapped file storage volume Dkron uses the local filesystem for storing the embedded database to store its own application data and the Raft protocol log. The end result is that your Dkron data will be on disk inside your container and lost if you ever remove the container.\nTo persist your data outside of the container and make it available for use between container launches we can mount a local path inside our container.\ndocker run -d -p 8080:8080 -v ~/dkron.data:/dkron.data --name dkron dkron/dkron agent --server --bootstrap-expect=1 Now when you launch your container we are mounting that folder from our local filesystem into the container.\n"
},
{
	"uri": "/v1.2/basics/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Running the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin.\nRun Dkron with default setting: dkron agent --server\nNavigate to http://localhost:8080\nBy default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA.\n Installing the package Debian repo APT repository:\ndeb [trusted=yes] https://apt.fury.io/distribworks/ / Then install: sudo apt-get install dkron\nYUM repo YUM repository:\n[dkron] name=Dkron Pro Private Repo baseurl=https://yum.fury.io/distribworks/ enabled=1 gpgcheck=0 Then install: sudo yum install dkron\nThis will start Dkron as a system service and the place example configuration file under /etc/dkron/dkron.yml\nRunning in Docker Dkron provides an official Docker image vi Dockerhub that can be used for deployment on any system running Docker.\nLaunching Dkron on a new container Here’s a quick one-liner to get you off the ground (please note, we recommend further configuration for production deployments below):\ndocker run -d -p 8080:8080 --name dkron dkron/dkron agent --server This will launch a Dkron server on port 8080 by default. You can use docker logs -f dkron to follow the rest of the initialization progress. Once the Dkron startup completes you can access the app at localhost:8080\nSince Docker containers have their own ports and we just map them to the system ports as needed it’s easy to move Dkron onto a different system port if you wish. For example running Dkron on port 12345:\ndocker run -d -p 12345:8080 --name dkron dkron/dkron Mounting a mapped file storage volume In its default configuration Dkron uses the local filesystem to run a BoltDB embedded database to store its own application data. The end result is that your Dkron application data will be on disk inside your container and lost if you ever remove the container.\nTo persist your data outside of the container and make it available for use between container launches we can mount a local file path inside our container.\ndocker run -d -p 8080:8080 -v ~/dkron.db:/dkron.db --name dkron dkron/dkron agent --server Now when you launch your container we are mounting that file from our local filesystem into the container.\n"
},
{
	"uri": "/v2.0/basics/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Running the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin.\nRun Dkron with default setting: dkron agent --server --bootstrap-expect=1\nNavigate to http://localhost:8080\nInstalling the package Debian repo APT repository:\ndeb [trusted=yes] https://apt.fury.io/distribworks/ / Then install: sudo apt-get install dkron\nYUM repo YUM repository:\n[dkron] name=Dkron Pro Private Repo baseurl=https://yum.fury.io/distribworks/ enabled=1 gpgcheck=0 Then install: sudo yum install dkron\nThis will start Dkron as a system service and the place example configuration file under /etc/dkron/dkron.yml\nRunning in Docker Dkron provides an official Docker image vi Dockerhub that can be used for deployment on any system running Docker.\nLaunching Dkron on a new container Here’s a quick one-liner to get you off the ground (please note, we recommend further configuration for production deployments below):\ndocker run -d -p 8080:8080 --name dkron dkron/dkron agent --server --bootstrap-expect=1 This will launch a Dkron server on port 8080 by default. You can use docker logs -f dkron to follow the rest of the initialization progress. Once the Dkron startup completes you can access the app at localhost:8080\nSince Docker containers have their own ports and we just map them to the system ports as needed it’s easy to move Dkron onto a different system port if you wish. For example running Dkron on port 12345:\ndocker run -d -p 12345:8080 --name dkron dkron/dkron Mounting a mapped file storage volume Dkron uses the local filesystem for storing the embedded database to store its own application data and the Raft protocol log. The end result is that your Dkron data will be on disk inside your container and lost if you ever remove the container.\nTo persist your data outside of the container and make it available for use between container launches we can mount a local path inside our container.\ndocker run -d -p 8080:8080 -v ~/dkron.data:/dkron.data --name dkron dkron/dkron agent --server --bootstrap-expect=1 Now when you launch your container we are mounting that folder from our local filesystem into the container.\n"
},
{
	"uri": "/v1.2/pro/quick-start/",
	"title": "Quick start",
	"tags": [],
	"description": "",
	"content": "Getting started Dkron Pro provides a clustering backend store out of the box based on etcd.\nTo configure the storage a sample etcd.conf.yaml file is provided in /etc/dkron path. Editing the file, allows to configure several options for the embedded store.\nThe location of the store configuration can be set in the command line or in the dkron config file /etc/dkron/dkron.yml using etcd-config-file-path parameter.\nStarting a single node Works out of the box, good for non HA installations.\n System service: If no changes are done to the default config files, dkron will start as a service in single mode. Command line: Running a single node with default config can be done by running: dkron agent --server  Check your server is working: curl localhost:8080/v1\nSimple as that, now it is time to add some jobs:\ncurl localhost:8080/v1/jobs -XPOST -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;Platform Team\u0026#34;, \u0026#34;owner_email\u0026#34;: \u0026#34;platform@example.com\u0026#34;, \u0026#34;disabled\u0026#34;: false, \u0026#34;tags\u0026#34;: { \u0026#34;dkron_server\u0026#34;: \u0026#34;true\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;allow\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;date\u0026#34; } }\u0026#39; "
},
{
	"uri": "/usage/target-nodes-spec/",
	"title": "Target nodes spec",
	"tags": [],
	"description": "",
	"content": "Target nodes spec Dkron has the ability to run jobs in specific nodes by leveraging the use of tags. You can choose whether a job is run on a node or group of nodes by specifying tags and a count of target nodes having this tag do you want a job to run.\nThe target node syntax is:\n\u0026quot;tag\u0026quot;: \u0026quot;value[:count]\u0026quot;  To achieve this Nodes and Jobs have tags, for example, having a node with the following tags:\n{ \u0026#34;tags\u0026#34;: { \u0026#34;dc\u0026#34;: \u0026#34;dc1\u0026#34;, \u0026#34;expect\u0026#34;: \u0026#34;3\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;6868\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;global\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;dkron\u0026#34;, \u0026#34;rpc_addr\u0026#34;: \u0026#34;10.88.94.129:6868\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;devel\u0026#34;, \u0026#34;my_role\u0026#34;: \u0026#34;web\u0026#34; } }  Tip: You can specify tags for nodes in the dkron config file or in the command line using --tags parameter Following some examples using different tag combinations:\nTarget all nodes with a tag { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;my_role#quot;: #quot;web#quot;\") --|Run Job|N1[\"Node1 tags: #quot;my_role#quot;: #quot;web#quot;\"] J --|Run Job|N2[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"] J --|Run Job|N3[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"]  Target only one nodes of a group of nodes with a tag { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web:1\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;my_role#quot;: #quot;web:1#quot;\") --|Run Job|N1[\"Node1 tags: #quot;my_role#quot;: #quot;web#quot;\"] J -.- N2[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"] J -.- N3[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"]  Dkron will try to run the job in the amount of nodes indicated by that count having that tag.\nDetails and limitations  Tags specified in a Job are combined using AND, therefore a job that specifies several tags like:  { \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;dkron\u0026#34; } } Will try to run the job in nodes that have all speciefied tags.\nThere is no limit in the tags that a job can have but having a Job with several tags with count like:\n{ \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web:1\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;dkron:2\u0026#34; } } Will try to run the job in nodes that have all specified tags and using the lowest count. In the last example, it will run in one node having \u0026quot;my_role\u0026quot;: \u0026quot;web\u0026quot; and \u0026quot;role\u0026quot;: \u0026quot;dkron\u0026quot; tag, even if there is more than one node with these tags.\n In case there is no matching nodes with the specified tags, the job will not run In case no tags are specified for a job it will run in all nodes in the cluster  "
},
{
	"uri": "/v1.2/usage/target-nodes-spec/",
	"title": "Target nodes spec",
	"tags": [],
	"description": "",
	"content": "Target nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run.\nThe target node syntax: [tag-value]:[count]\n Examples: Target all nodes with a tag:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;role#quot;: #quot;web#quot;\") --|Run Job|N1[\"Node1 tags: #quot;role#quot;: #quot;web#quot;\"] J --|Run Job|N2[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"] J --|Run Job|N3[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"]  Target only one nodes of a group of nodes with a tag:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web:1\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;role#quot;: #quot;web:1#quot;\") --|Run Job|N1[\"Node1 tags: #quot;role#quot;: #quot;web#quot;\"] J -.- N2[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"] J -.- N3[\"Node2 tags: #quot;role#quot;: #quot;web#quot;\"]  Dkron will try to run the job in the amount of nodes indicated by that count having that tag.\n"
},
{
	"uri": "/v2.0/usage/target-nodes-spec/",
	"title": "Target nodes spec",
	"tags": [],
	"description": "",
	"content": "Target nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run.\nThe target node syntax: [tag-value]:[count]\n Examples: Target all nodes with a tag:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;my_role#quot;: #quot;web#quot;\") --|Run Job|N1[\"Node1 tags: #quot;my_role#quot;: #quot;web#quot;\"] J --|Run Job|N2[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"] J --|Run Job|N3[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"]  Target only one nodes of a group of nodes with a tag:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web:1\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;my_role#quot;: #quot;web:1#quot;\") --|Run Job|N1[\"Node1 tags: #quot;my_role#quot;: #quot;web#quot;\"] J -.- N2[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"] J -.- N3[\"Node2 tags: #quot;my_role#quot;: #quot;web#quot;\"]  Dkron will try to run the job in the amount of nodes indicated by that count having that tag.\n"
},
{
	"uri": "/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " Installation\nRunning the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin. Run Dkron with default setting: dkron agent --server --bootstrap-expect=1 Navigate to http://localhost:8080 Installing the package Debian repo APT repository: deb [trusted=yes] https://repo.distrib.works/apt/ / Then install: sudo apt-get install dkron YUM repo YUM repository: [dkron] name=Dkron Pro Private Repo baseurl=https://repo.distrib.works/yum/ enabled=1 gpgcheck=0 Then install: sudo yum install dkron\n  Getting started\nIntroduction Dkron nodes can work in two modes, agents or servers. A Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server. A Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too. The main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\n  Configuration\nConfiguration sources Settings can be specified in three ways (in order of precedence): Command line arguments. Environment variables starting with DKRON_ dkron.yml config file Config file location Config file will be loaded from the following paths: /etc/dkron $HOME/.dkron ./config Config file example # Dkron example configuration file # server: false # bootstrap-expect: 3 # data-dir: dkron.data # log-level: debug # tags: # dc: east # encrypt: a-valid-key-generated-with-dkron-keygen # retry-join: # - 10.\n  "
},
{
	"uri": "/v1.2/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " Installation\nRunning the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin. Run Dkron with default setting: dkron agent --server Navigate to http://localhost:8080 By default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA. Installing the package Debian repo APT repository:\n  Getting started\nIntroduction Dkron nodes can work in two modes, agents or servers. A Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server. A Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too. The main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\n  Configuration\nConfiguration sources Settings can be specified in three ways (in order of precedence): Command line arguments. Environment variables starting with DKRON_ dkron.json config file Config file example # Dkron example configuration file # backend: etcd # backend-machine: 127.0.0.1:2379 # server: false # log-level: debug # tags: # role: web # datacenter: east # keyspace: dkron # encrypt: a-valid-key-generated-with-dkron-keygen # join: # - 10.0.0.1 # - 10.0.0.2 # - 10.\n  "
},
{
	"uri": "/v2.0/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " Installation\nRunning the binary Download the packaged archive for your platform from the downloads page and extract the package to a shared location in your drive, like /opt/local/bin. Run Dkron with default setting: dkron agent --server --bootstrap-expect=1 Navigate to http://localhost:8080 Installing the package Debian repo APT repository: deb [trusted=yes] https://apt.fury.io/distribworks/ / Then install: sudo apt-get install dkron YUM repo YUM repository: [dkron] name=Dkron Pro Private Repo baseurl=https://yum.fury.io/distribworks/ enabled=1 gpgcheck=0 Then install: sudo yum install dkron\n  Getting started\nIntroduction Dkron nodes can work in two modes, agents or servers. A Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server. A Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too. The main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\n  Configuration\nConfiguration sources Settings can be specified in three ways (in order of precedence): Command line arguments. Environment variables starting with DKRON_ dkron.yml config file Config file location Config file will be loaded from the following paths: /etc/dkron $HOME/.dkron ./config Config file example # Dkron example configuration file # server: false # bootstrap-expect: 3 # data-dir: dkron.data # log-level: debug # tags: # dc: east # encrypt: a-valid-key-generated-with-dkron-keygen # retry-join: # - 10.\n  "
},
{
	"uri": "/usage/cron-spec/",
	"title": "Cron spec",
	"tags": [],
	"description": "",
	"content": "CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields.\nField name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ? Month | Yes | 1-12 or JAN-DEC | * / , - Day of week | Yes | 0-6 or SUN-SAT | * / , - ?  Note: Month and Day-of-week field values are case insensitive. \u0026ldquo;SUN\u0026rdquo;, \u0026ldquo;Sun\u0026rdquo;, and \u0026ldquo;sun\u0026rdquo; are equally accepted.\nSpecial Characters\nAsterisk ( * )\nThe asterisk indicates that the cron expression will match for all values of the field; e.g., using an asterisk in the 5th field (month) would indicate every month.\nSlash ( / )\nSlashes are used to describe increments of ranges. For example 3-59/15 in the 1st field (minutes) would indicate the 3rd minute of the hour and every 15 minutes thereafter. The form \u0026ldquo;*/\u0026hellip;\u0026rdquo; is equivalent to the form \u0026ldquo;first-last/\u0026hellip;\u0026quot;, that is, an increment over the largest possible range of the field. The form \u0026ldquo;N/\u0026hellip;\u0026rdquo; is accepted as meaning \u0026ldquo;N-MAX/\u0026hellip;\u0026quot;, that is, starting at N, use the increment until the end of that specific range. It does not wrap around.\nComma ( , )\nCommas are used to separate items of a list. For example, using \u0026ldquo;MON,WED,FRI\u0026rdquo; in the 5th field (day of week) would mean Mondays, Wednesdays and Fridays.\nHyphen ( - )\nHyphens are used to define ranges. For example, 9-17 would indicate every hour between 9am and 5pm inclusive.\nQuestion mark ( ? )\nQuestion mark may be used instead of \u0026lsquo;*\u0026rsquo; for leaving either day-of-month or day-of-week blank.\nPredefined schedules You may use one of several pre-defined schedules in place of a cron expression.\nEntry | Description | Equivalent To ----- | ----------- | ------------- @yearly (or @annually) | Run once a year, midnight, Jan. 1st | 0 0 0 1 1 * @monthly | Run once a month, midnight, first of month | 0 0 0 1 * * @weekly | Run once a week, midnight on Sunday | 0 0 0 * * 0 @daily (or @midnight) | Run once a day, midnight | 0 0 0 * * * @hourly | Run once an hour, beginning of hour | 0 0 * * * * @minutely | Run once a minute, beginning of minute | 0 * * * * * @manually | Never runs | N/A  Intervals You may also schedule a job to execute at fixed intervals. This is supported by formatting the cron spec like this:\n@every \u0026lt;duration\u0026gt;  where \u0026ldquo;duration\u0026rdquo; is a string accepted by time.ParseDuration (http://golang.org/pkg/time/#ParseDuration).\nFor example, \u0026ldquo;@every 1h30m10s\u0026rdquo; would indicate a schedule that activates every 1 hour, 30 minutes, 10 seconds.\nNote: The interval does not take the job runtime into account. For example, if a job takes 3 minutes to run, and it is scheduled to run every 5 minutes, it will have only 2 minutes of idle time between each run.\nFixed times You may also want to schedule a job to be executed once. This is supported by formatting the cron spec like this:\n@at \u0026lt;datetime\u0026gt;  Where \u0026ldquo;datetime\u0026rdquo; is a string accepted by time.Parse in RFC3339 format (https://golang.org/pkg/time/#Parse).\nFor example, \u0026ldquo;@at 2018-01-02T15:04:00Z\u0026rdquo; would run the job on the specified date and time assuming UTC timezone.\nTime zones Dkron is able to schedule jobs in time zones, if you specify the timezone parameter in a job definition.\nIf the time zone is not specified, the following rules apply:\nAll interpretation and scheduling is done in the machine\u0026rsquo;s local time zone (as provided by the Go time package (http://www.golang.org/pkg/time).\nBe aware that jobs scheduled during daylight-savings leap-ahead transitions will not be run!\nIf you specify timezone the job will be scheduled taking into account daylight-savings and leap-ahead transitions, running the job in the actual time in the specified time zone.\n"
},
{
	"uri": "/v1.2/usage/cron-spec/",
	"title": "Cron spec",
	"tags": [],
	"description": "",
	"content": "CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields.\nField name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ? Month | Yes | 1-12 or JAN-DEC | * / , - Day of week | Yes | 0-6 or SUN-SAT | * / , - ?  Note: Month and Day-of-week field values are case insensitive. \u0026ldquo;SUN\u0026rdquo;, \u0026ldquo;Sun\u0026rdquo;, and \u0026ldquo;sun\u0026rdquo; are equally accepted.\nSpecial Characters\nAsterisk ( * )\nThe asterisk indicates that the cron expression will match for all values of the field; e.g., using an asterisk in the 5th field (month) would indicate every month.\nSlash ( / )\nSlashes are used to describe increments of ranges. For example 3-59/15 in the 1st field (minutes) would indicate the 3rd minute of the hour and every 15 minutes thereafter. The form \u0026ldquo;*/\u0026hellip;\u0026rdquo; is equivalent to the form \u0026ldquo;first-last/\u0026hellip;\u0026quot;, that is, an increment over the largest possible range of the field. The form \u0026ldquo;N/\u0026hellip;\u0026rdquo; is accepted as meaning \u0026ldquo;N-MAX/\u0026hellip;\u0026quot;, that is, starting at N, use the increment until the end of that specific range. It does not wrap around.\nComma ( , )\nCommas are used to separate items of a list. For example, using \u0026ldquo;MON,WED,FRI\u0026rdquo; in the 5th field (day of week) would mean Mondays, Wednesdays and Fridays.\nHyphen ( - )\nHyphens are used to define ranges. For example, 9-17 would indicate every hour between 9am and 5pm inclusive.\nQuestion mark ( ? )\nQuestion mark may be used instead of \u0026lsquo;*\u0026rsquo; for leaving either day-of-month or day-of-week blank.\nPredefined schedules You may use one of several pre-defined schedules in place of a cron expression.\nEntry | Description | Equivalent To ----- | ----------- | ------------- @yearly (or @annually) | Run once a year, midnight, Jan. 1st | 0 0 0 1 1 * @monthly | Run once a month, midnight, first of month | 0 0 0 1 * * @weekly | Run once a week, midnight on Sunday | 0 0 0 * * 0 @daily (or @midnight) | Run once a day, midnight | 0 0 0 * * * @hourly | Run once an hour, beginning of hour | 0 0 * * * * @minutely | Run once a minute, beginning of minute | 0 * * * * *  Intervals You may also schedule a job to execute at fixed intervals. This is supported by formatting the cron spec like this:\n@every \u0026lt;duration\u0026gt;  where \u0026ldquo;duration\u0026rdquo; is a string accepted by time.ParseDuration (http://golang.org/pkg/time/#ParseDuration).\nFor example, \u0026ldquo;@every 1h30m10s\u0026rdquo; would indicate a schedule that activates every 1 hour, 30 minutes, 10 seconds.\nNote: The interval does not take the job runtime into account. For example, if a job takes 3 minutes to run, and it is scheduled to run every 5 minutes, it will have only 2 minutes of idle time between each run.\nFixed times You may also want to schedule a job to be executed once. This is supported by formatting the cron spec like this:\n@at \u0026lt;datetime\u0026gt;  Where \u0026ldquo;datetime\u0026rdquo; is a string accepted by time.Parse in RFC3339 format (https://golang.org/pkg/time/#Parse).\nFor example, \u0026ldquo;@at 2018-01-02T15:04:00Z\u0026rdquo; would run the job on the specified date and time assuming UTC timezone.\nTime zones Dkron is able to schedule jobs in time zones, if you specify the timezone parameter in a job definition.\nIf the time zone is not specified, the following rules apply:\nAll interpretation and scheduling is done in the machine\u0026rsquo;s local time zone (as provided by the Go time package (http://www.golang.org/pkg/time).\nBe aware that jobs scheduled during daylight-savings leap-ahead transitions will not be run!\nIf you specify timezone the job will be scheduled taking into account daylight-savings and leap-ahead transitions, running the job in the actual time in the specified time zone.\n"
},
{
	"uri": "/v2.0/usage/cron-spec/",
	"title": "Cron spec",
	"tags": [],
	"description": "",
	"content": "CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields.\nField name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ? Month | Yes | 1-12 or JAN-DEC | * / , - Day of week | Yes | 0-6 or SUN-SAT | * / , - ?  Note: Month and Day-of-week field values are case insensitive. \u0026ldquo;SUN\u0026rdquo;, \u0026ldquo;Sun\u0026rdquo;, and \u0026ldquo;sun\u0026rdquo; are equally accepted.\nSpecial Characters\nAsterisk ( * )\nThe asterisk indicates that the cron expression will match for all values of the field; e.g., using an asterisk in the 5th field (month) would indicate every month.\nSlash ( / )\nSlashes are used to describe increments of ranges. For example 3-59/15 in the 1st field (minutes) would indicate the 3rd minute of the hour and every 15 minutes thereafter. The form \u0026ldquo;*/\u0026hellip;\u0026rdquo; is equivalent to the form \u0026ldquo;first-last/\u0026hellip;\u0026quot;, that is, an increment over the largest possible range of the field. The form \u0026ldquo;N/\u0026hellip;\u0026rdquo; is accepted as meaning \u0026ldquo;N-MAX/\u0026hellip;\u0026quot;, that is, starting at N, use the increment until the end of that specific range. It does not wrap around.\nComma ( , )\nCommas are used to separate items of a list. For example, using \u0026ldquo;MON,WED,FRI\u0026rdquo; in the 5th field (day of week) would mean Mondays, Wednesdays and Fridays.\nHyphen ( - )\nHyphens are used to define ranges. For example, 9-17 would indicate every hour between 9am and 5pm inclusive.\nQuestion mark ( ? )\nQuestion mark may be used instead of \u0026lsquo;*\u0026rsquo; for leaving either day-of-month or day-of-week blank.\nPredefined schedules You may use one of several pre-defined schedules in place of a cron expression.\nEntry | Description | Equivalent To ----- | ----------- | ------------- @yearly (or @annually) | Run once a year, midnight, Jan. 1st | 0 0 0 1 1 * @monthly | Run once a month, midnight, first of month | 0 0 0 1 * * @weekly | Run once a week, midnight on Sunday | 0 0 0 * * 0 @daily (or @midnight) | Run once a day, midnight | 0 0 0 * * * @hourly | Run once an hour, beginning of hour | 0 0 * * * * @minutely | Run once a minute, beginning of minute | 0 * * * * * @manually | Never runs | N/A  Intervals You may also schedule a job to execute at fixed intervals. This is supported by formatting the cron spec like this:\n@every \u0026lt;duration\u0026gt;  where \u0026ldquo;duration\u0026rdquo; is a string accepted by time.ParseDuration (http://golang.org/pkg/time/#ParseDuration).\nFor example, \u0026ldquo;@every 1h30m10s\u0026rdquo; would indicate a schedule that activates every 1 hour, 30 minutes, 10 seconds.\nNote: The interval does not take the job runtime into account. For example, if a job takes 3 minutes to run, and it is scheduled to run every 5 minutes, it will have only 2 minutes of idle time between each run.\nFixed times You may also want to schedule a job to be executed once. This is supported by formatting the cron spec like this:\n@at \u0026lt;datetime\u0026gt;  Where \u0026ldquo;datetime\u0026rdquo; is a string accepted by time.Parse in RFC3339 format (https://golang.org/pkg/time/#Parse).\nFor example, \u0026ldquo;@at 2018-01-02T15:04:00Z\u0026rdquo; would run the job on the specified date and time assuming UTC timezone.\nTime zones Dkron is able to schedule jobs in time zones, if you specify the timezone parameter in a job definition.\nIf the time zone is not specified, the following rules apply:\nAll interpretation and scheduling is done in the machine\u0026rsquo;s local time zone (as provided by the Go time package (http://www.golang.org/pkg/time).\nBe aware that jobs scheduled during daylight-savings leap-ahead transitions will not be run!\nIf you specify timezone the job will be scheduled taking into account daylight-savings and leap-ahead transitions, running the job in the actual time in the specified time zone.\n"
},
{
	"uri": "/usage/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": "Executors Executor plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes.\nFor example, the built-in shell executor, will run the indicated command in the target node.\nNew plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\n HTTP Executor \n Shell Executor \n If you need more features you can check Dkron Pro that brings commercially supported plugins.\n"
},
{
	"uri": "/v1.2/usage/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": "Executors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes.\nFor example, the built-in shell executor, will run the indicated command in the target node.\nNew plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\nDkron Pro have commercially supported executors\n HTTP Executor \n Shell Executor \n "
},
{
	"uri": "/v2.0/usage/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": "Executors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes.\nFor example, the built-in shell executor, will run the indicated command in the target node.\nNew plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\nDkron Pro have commercially supported executors\n HTTP Executor \n Shell Executor \n "
},
{
	"uri": "/basics/getting-started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": "Introduction Dkron nodes can work in two modes, agents or servers.\nA Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server.\nA Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too.\nThe main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\nDkron clusters have a leader, the leader is responsible of starting job execution queries in the cluster.\nAny Dkron agent or server acts as a cluster member and it\u0026rsquo;s available to run scheduled jobs.\nYou can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. This gives an unprecedented level of flexibility in runnig jobs across a cluster of any size and with any combination of machines you need.\nAll the execution responses will be gathered by the scheduler and stored in the database.\nState storage Dkron deployment is just a single binary, it stores the state in an internal BuntDB instance and replicate all changes between all server nodes using the Raft protocol, it doesn\u0026rsquo;t need any other storage system outside itself.\nInstallation See the installation.\nConfiguration See the configuration.\nUsage By default Dkron uses the following ports:\n 8946 for serf layer between agents 8080 for HTTP for the API and Dashboard 6868 for gRPC and raft layer comunication between agents.  Be sure you have opened this ports (or the ones that you configured) in your firewall or AWS security groups.\n Starting a single node Works out of the box, good for non HA installations.\n System service: If no changes are done to the default config files, dkron will start as a service in single mode. Command line: Running a single node with default config can be done by running:  dkron agent --server --bootstrap-expect=1 Check your server is working: curl localhost:8080/v1\nFor a full list of configuration parameters and its description, see the CLI docs\n Create a Job This job will only run in just one server node due to the node count in the tag. Refer to the target node spec for details.\n curl localhost:8080/v1/jobs -XPOST -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;Platform Team\u0026#34;, \u0026#34;owner_email\u0026#34;: \u0026#34;platform@example.com\u0026#34;, \u0026#34;disabled\u0026#34;: false, \u0026#34;tags\u0026#34;: { \u0026#34;server\u0026#34;: \u0026#34;true:1\u0026#34; }, \u0026#34;metadata\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;12345\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;allow\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;date\u0026#34; } }\u0026#39; For full Job params description refer to the Job model in the API guide\nThat\u0026rsquo;s it!\nTo start configuring an HA installation of Dkron follow the clustering guide "
},
{
	"uri": "/v1.2/basics/getting-started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": "Introduction Dkron nodes can work in two modes, agents or servers.\nA Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server.\nA Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too.\nThe main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\nDkron clusters have a leader, the leader is responsible of starting job execution queries in the cluster.\nAny Dkron agent or server acts as a cluster member and it\u0026rsquo;s available to run scheduled jobs.\nYou can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. This gives an unprecedented level of flexibility in runnig jobs across a cluster of any size and with any combination of machines you need.\nAll the execution responses will be gathered by the scheduler and stored in the database.\nBackend stores Dkron relies on the key-value store for data storage, an instance of the distributed store can be run in the same machines as Dkron or connect it to an already existing cluster.\nBy default dkron will start with a file based, embedded KV store called BoltDB, it is functional for a single node demo but does not offers clustering or HA.\n It is compatible with etcd, Consul, Zookeeper, Redis, DynamoDB and BoltDB. For instructions on how to install and configure any one of these systems refer to their official sites:\n etcd Consul ZooKeeper Redis DynamoDB  Installation See the installation.\nConfiguration See the configuration.\nUsage By default Dkron uses the following ports:\n 8946 for communicating between agents 8080 for HTTP for the API and Dashboard 6868 for RPC comunication between agents.  Be sure you have opened this ports (or the ones that you configured) in your firewall or AWS security groups.\n By default dkron will use the embedded BoltDB KV store. A different store can be specified setting backend and backend-machines flag in the config file, env variables or as a command line flag.\nTo start a Dkron server instance:\ndkron agent --server Time to add the first job:\nThis job will only run in just one dkron_server node due to the node count in the tag. Refer to the target node spec for details.\n curl localhost:8080/v1/jobs -XPOST -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;Platform Team\u0026#34;, \u0026#34;owner_email\u0026#34;: \u0026#34;platform@example.com\u0026#34;, \u0026#34;disabled\u0026#34;: false, \u0026#34;tags\u0026#34;: { \u0026#34;dkron_server\u0026#34;: \u0026#34;true:1\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;allow\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;date\u0026#34; } }` That\u0026rsquo;s it!\nTo start configuring an HA installation of Dkron follow the clustering guide "
},
{
	"uri": "/v2.0/basics/getting-started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": "Introduction Dkron nodes can work in two modes, agents or servers.\nA Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server.\nA Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too.\nThe main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\nDkron clusters have a leader, the leader is responsible of starting job execution queries in the cluster.\nAny Dkron agent or server acts as a cluster member and it\u0026rsquo;s available to run scheduled jobs.\nYou can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. This gives an unprecedented level of flexibility in runnig jobs across a cluster of any size and with any combination of machines you need.\nAll the execution responses will be gathered by the scheduler and stored in the database.\nState storage Dkron deployment is just a single binary, it stores the state in an internal BadgerDB instance and replicate all changes between all server nodes using the Raft protocol, it doesn\u0026rsquo;t need any other storage system outside itself.\nInstallation See the installation.\nConfiguration See the configuration.\nUsage By default Dkron uses the following ports:\n 8946 for serf layer between agents 8080 for HTTP for the API and Dashboard 6868 for gRPC and raft layer comunication between agents.  Be sure you have opened this ports (or the ones that you configured) in your firewall or AWS security groups.\n Starting a single node Works out of the box, good for non HA installations.\n System service: If no changes are done to the default config files, dkron will start as a service in single mode. Command line: Running a single node with default config can be done by running:  dkron agent --server --bootstrap-expect=1 Check your server is working: curl localhost:8080/v1\nSimple as that, now it is time to add a job:\nThis job will only run in just one server node due to the node count in the tag. Refer to the target node spec for details.\n curl localhost:8080/v1/jobs -XPOST -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;timezone\u0026#34;: \u0026#34;Europe/Berlin\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;Platform Team\u0026#34;, \u0026#34;owner_email\u0026#34;: \u0026#34;platform@example.com\u0026#34;, \u0026#34;disabled\u0026#34;: false, \u0026#34;tags\u0026#34;: { \u0026#34;server\u0026#34;: \u0026#34;true\u0026#34; }, \u0026#34;metadata\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;12345\u0026#34; } \u0026#34;concurrency\u0026#34;: \u0026#34;allow\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;date\u0026#34; } }\u0026#39; For full Job params description refer to the Job model in the API guide\nThat\u0026rsquo;s it!\nTo start configuring an HA installation of Dkron follow the clustering guide "
},
{
	"uri": "/usage/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": "Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do:\n Execution output storage, forwarding or redirection. Notification Monitoring  For example, Processor plugins can be used to redirect the output of a job execution to different targets.\nCurrently Dkron provides you with some built-in plugins but the list keeps growing. Some of the features previously implemented in the application will be progessively moved to plugins.\nBuilt-in processors Dkron provides the following built-in processors:\nnot specified - Store the output in the key value store (Slow performance, good for testing, default method) log - Output the execution log to Dkron stdout (Good performance, needs parsing) syslog - Output to the syslog (Good performance, needs parsing) files - Output to multiple files (Good performance, needs parsing)  Dkro Pro provides you with several more processors.\nAll plugins accepts one configuration option: forward Indicated if the plugin must forward the original execution output. This allows for chaining plugins and sending output to different targets at the same time.\n File Processor \n Log Processor \n Syslog Processor \n "
},
{
	"uri": "/v1.2/usage/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": "Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do:\n Execution output storage, forwarding or redirection. Notification Monitoring  For example, Processor plugins can be used to redirect the output of a job execution to different targets.\nCurrently Dkron provides you with some built-in plugins but the list keeps growing. Some of the features previously implemented in the application will be progessively moved to plugins.\nBuilt-in processors Dkron provides the following built-in processors:\nnot specified - Store the output in the key value store (Slow performance, good for testing, default method) log - Output the execution log to Dkron stdout (Good performance, needs parsing) syslog - Output to the syslog (Good performance, needs parsing) files - Output to multiple files (Good performance, needs parsing)  Dkro Pro provides you with several more processors.\nAll plugins accepts one configuration option: forward Indicated if the plugin must forward the original execution output. This allows for chaining plugins and sending output to different targets at the same time.\n File Processor \n Log Processor \n Syslog Processor \n "
},
{
	"uri": "/v2.0/usage/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": "Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do:\n Execution output storage, forwarding or redirection. Notification Monitoring  For example, Processor plugins can be used to redirect the output of a job execution to different targets.\nCurrently Dkron provides you with some built-in plugins but the list keeps growing. Some of the features previously implemented in the application will be progessively moved to plugins.\nBuilt-in processors Dkron provides the following built-in processors:\nnot specified - Store the output in the key value store (Slow performance, good for testing, default method) log - Output the execution log to Dkron stdout (Good performance, needs parsing) syslog - Output to the syslog (Good performance, needs parsing) files - Output to multiple files (Good performance, needs parsing)  Dkro Pro provides you with several more processors.\nAll plugins accepts one configuration option: forward Indicated if the plugin must forward the original execution output. This allows for chaining plugins and sending output to different targets at the same time.\n File Processor \n Log Processor \n Syslog Processor \n "
},
{
	"uri": "/usage/",
	"title": "Usage",
	"tags": [],
	"description": "",
	"content": " Target nodes spec\nTarget nodes spec Dkron has the ability to run jobs in specific nodes by leveraging the use of tags. You can choose whether a job is run on a node or group of nodes by specifying tags and a count of target nodes having this tag do you want a job to run. The target node syntax is: \u0026quot;tag\u0026quot;: \u0026quot;value[:count]\u0026quot; To achieve this Nodes and Jobs have tags, for example, having a node with the following tags:\n  Cron spec\nCRON Expression Format A cron expression represents a set of times, using 6 space-separated fields. Field name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ?\n  Executors\nExecutors Executor plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes. For example, the built-in shell executor, will run the indicated command in the target node. New plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\n  HTTP Executor\nHTTP executor can send a request to an HTTP endpoint Configuration Params: method: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty tlsNoVerifyPeer: false (default) or true. If true, disables verification of the remote SSL certificate's validity.\n  Shell Executor\nShell executor runs a system command Configuration Params shell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example { \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } }   Processors\nExecution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do: Execution output storage, forwarding or redirection. Notification Monitoring For example, Processor plugins can be used to redirect the output of a job execution to different targets.\n  File Processor\nFile processor saves the execution output to a single log file in the specified directory Configuration Parameters log_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: \u0026#34;true\u0026#34; } } }   Log Processor\nLog processor writes the execution output to stdout/stderr Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: \u0026#34;true\u0026#34; } } }   Syslog Processor\nSyslog processor writes the execution output to the system syslog daemon Note: Only work on linux systems Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: \u0026#34;true\u0026#34; } } }   Cloud Auto-join\nDkron supports automatic cluster joining using cloud metadata on various providers.\n  Clustering\nConfigure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run. Manually bootstrapping a Dkron cluster does not rely on additional tooling, but does require operator participation in the cluster formation process. When bootstrapping, Dkron servers and clients must be started and informed with the address of at least one Dkron server.\n  Concurrency\nConcurrency Jobs can be configured to allow overlapping executions or forbid them. Concurrency property accepts two option: allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule. Example: { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; }   Embedded storage\nDkron has an embedded distributed KV store engine based on BuntDB. This works out of the box on each dkron server. This ensures a dead easy install and setup, basically run dkron and you will have a full working node.\n  Job chaining\nJob chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job. The dependent job will be executed after the main job finished a successful execution. Child jobs schedule property will be ignored if it\u0026rsquo;s present. Take into account that parent jobs must be created before any child job.\n  Job metadata\nJob metadata Jobs can have an optional extra property field called metadata that allows to set arbitrary tags to jobs and query the jobs using the API: { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;user_id\u0026#34;: \u0026#34;12345\u0026#34; } } And then query the API to get only the results needed: $ curl http://localhost:8080/v1/jobs --data-urlencode \u0026quot;metadata[user_id]=12345\u0026quot;`   Job retries\nJobs can be configured to retry in case of failure. Configuration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n  Metrics\nDkron has the ability to send metrics to Statsd for dashboards and historical reporting or provide prometheus format metrics via the api. It sends job processing metrics, golang, and serf metrics. Configuration Statsd Add this in your yaml config file to enable statsd metrics. statsd-addr: \u0026#34;localhost:8125\u0026#34; # Or for datadog statsd dog-statsd-addr: \u0026#34;localhost:8125\u0026#34; Prometheus Add this to your yaml config file to enable serving prometheus metrics at the endpoint /metrics\n  Outage recovery\nOutage Recovery Don\u0026rsquo;t panic! This is a critical first step. Depending on your deployment configuration, it may take only a single server failure for cluster unavailability. Recovery requires an operator to intervene, but the process is straightforward. This guide is for recovery from a Dkron outage due to a majority of server nodes in a datacenter being lost. If you are looking to add or remove servers, see the clustering guide.\n  Plugins\nIntro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs. This page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin. How it Works Dkron execution execution processors are provided via plugins.\n  Developing plugins\nDeveloping a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language. Note: A common pitfall is not properly setting up a $GOPATH.\n  Upgrade methods\nUse one of the following methods (depending on the changes) to upgrade a cluster to a newer version. Rolling upgrade Use the following procedure to rotate all cluster nodes, one server at a time: Add a new servers to the cluster with a configuration that joins them to the existing cluter. Stop dkron service in one of the old servers, if it was the leader allow a new leader to be ellected, note that it is better to remove the current leader at the end, to ensure a leader is elected between the new nodes.\n  Use with AWS ECS\nDkron Pro comes with a native ECS executor out of the box. Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed. Install the following snippet in the node that will run the call to ECS Prerequisites The node that will run the call to ECS will need to have installed AWS cli jq Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n  "
},
{
	"uri": "/v1.2/usage/",
	"title": "Usage",
	"tags": [],
	"description": "",
	"content": " Target nodes spec\nTarget nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. The target node syntax: [tag-value]:[count] Examples: Target all nodes with a tag: { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;role#quot;: #quot;web#quot;\") --|Run Job|N1[\"\n  Cron spec\nCRON Expression Format A cron expression represents a set of times, using 6 space-separated fields. Field name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ?\n  Executors\nExecutors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes. For example, the built-in shell executor, will run the indicated command in the target node. New plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\n  HTTP Executor\nHTTP executor can send a request to an HTTP endpoint Configuration Params: method: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty Example { \u0026#34;executor\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://example.\n  Shell Executor\nShell executor runs a system command Configuration Params shell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example { \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } }   Processors\nExecution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do: Execution output storage, forwarding or redirection. Notification Monitoring For example, Processor plugins can be used to redirect the output of a job execution to different targets.\n  File Processor\nFile processor saves the execution output to a single log file in the specified directory Configuration Parameters log_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: true } } }   Log Processor\nLog processor writes the execution output to stdout/stderr Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }   Syslog Processor\nSyslog processor writes the execution output to the system syslog daemon Note: Only work on linux systems Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }   Clustering\nConfigure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run. To form a cluster, server nodes need to know the address of its peers as in the following example: # dkron.yml join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 Etcd For a more in detail guide of clustering with etcd follow this guide: https://github.\n  Concurrency\nConcurrency Jobs can be configured to allow overlapping executions or forbid them. Concurrency property accepts two option: allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule. Example: { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; }   Internals\nThis document is a WIP, it\u0026rsquo;s intended to describe the reasons that lead to design decisions in Dkron. Execution results Dkron store the result of each job execution in each node. Every time dkron executes a job it assigns it an execution group, generating a new uuid and send a serf query to target machines and waits for a response. Each target machine that will run the job, then responds with an execution object saying it started to run the job.\n  Job chaining\nJob chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job. The dependent job will be executed after the main job finished a successful execution. Child jobs schedule property will be ignored if it\u0026rsquo;s present. Take into account that parent jobs must be created before any child job.\n  Job retries\nJobs can be configured to retry in case of failure. Configuration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n  Metrics\nDkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too. Configuration Add this in your yaml config file dog_statsd_addr: \u0026#34;localhost:8125\u0026#34; Metrics dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query   Plugins\nIntro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs. This page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin. How it Works Dkron execution execution processors are provided via plugins.\n  Developing plugins\nDeveloping a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language. Note: A common pitfall is not properly setting up a $GOPATH.\n  Use with AWS ECS\nDkron Pro comes with a native ECS executor out of the box. Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed. Install the following snippet in the node that will run the call to ECS Prerequisites The node that will run the call to ECS will need to have installed AWS cli jq Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n  "
},
{
	"uri": "/v2.0/usage/",
	"title": "Usage",
	"tags": [],
	"description": "",
	"content": " Target nodes spec\nTarget nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. The target node syntax: [tag-value]:[count] Examples: Target all nodes with a tag: { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;my_role\u0026#34;: \u0026#34;web\u0026#34; } } mermaid.initialize({startOnLoad:true}); graph LR; J(\"Job tags: #quot;my_role#quot;: #quot;web#quot;\") --|Run Job|N1[\"\n  Cron spec\nCRON Expression Format A cron expression represents a set of times, using 6 space-separated fields. Field name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ?\n  Executors\nExecutors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes. For example, the built-in shell executor, will run the indicated command in the target node. New plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\n  HTTP Executor\nHTTP executor can send a request to an HTTP endpoint Configuration Params: method: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty tlsNoVerifyPeer: false (default) or true. If true, disables verification of the remote SSL certificate's validity.\n  Shell Executor\nShell executor runs a system command Configuration Params shell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example { \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } }   Processors\nExecution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do: Execution output storage, forwarding or redirection. Notification Monitoring For example, Processor plugins can be used to redirect the output of a job execution to different targets.\n  File Processor\nFile processor saves the execution output to a single log file in the specified directory Configuration Parameters log_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: true } } }   Log Processor\nLog processor writes the execution output to stdout/stderr Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }   Syslog Processor\nSyslog processor writes the execution output to the system syslog daemon Note: Only work on linux systems Configuration Parameters forward: Forward the output to the next processor Example { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: true } } }   Cloud Auto-join\nDkron supports automatic cluster joining using cloud metadata on various providers.\n  Clustering\nConfigure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run. Manually bootstrapping a Dkron cluster does not rely on additional tooling, but does require operator participation in the cluster formation process. When bootstrapping, Dkron servers and clients must be started and informed with the address of at least one Dkron server.\n  Concurrency\nConcurrency Jobs can be configured to allow overlapping executions or forbid them. Concurrency property accepts two option: allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule. Example: { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; }   Embedded storage\nDkron has an embedded distributed KV store engine based on BadgerDB. This works out of the box on each dkron server. This ensures a dead easy install and setup, basically run dkron and you will have a full working node.\n  Job chaining\nJob chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job. The dependent job will be executed after the main job finished a successful execution. Child jobs schedule property will be ignored if it\u0026rsquo;s present. Take into account that parent jobs must be created before any child job.\n  Job metadata\nJob metadata Jobs can have an optional extra property field called metadata that allows to set arbitrary tags to jobs and query the jobs using the API: { \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;user_id\u0026#34;: \u0026#34;12345\u0026#34; } } And then query the API to get only the results needed: $ curl http://localhost:8080/v1/jobs --data-urlencode \u0026quot;metadata[user_id]=12345\u0026quot;`   Job retries\nJobs can be configured to retry in case of failure. Configuration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n  Metrics\nDkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too. Configuration Add this in your yaml config file dog_statsd_addr: \u0026#34;localhost:8125\u0026#34; Metrics dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query   Outage recovery\nOutage Recovery Don\u0026rsquo;t panic! This is a critical first step. Depending on your deployment configuration, it may take only a single server failure for cluster unavailability. Recovery requires an operator to intervene, but the process is straightforward. This guide is for recovery from a Dkron outage due to a majority of server nodes in a datacenter being lost. If you are looking to add or remove servers, see the clustering guide.\n  Plugins\nIntro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs. This page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin. How it Works Dkron execution execution processors are provided via plugins.\n  Developing plugins\nDeveloping a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language. Note: A common pitfall is not properly setting up a $GOPATH.\n  Use with AWS ECS\nDkron Pro comes with a native ECS executor out of the box. Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed. Install the following snippet in the node that will run the call to ECS Prerequisites The node that will run the call to ECS will need to have installed AWS cli jq Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n  "
},
{
	"uri": "/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": " Pro CLI \n  dkron \n   dkron agent \n   dkron doc \n   dkron keygen \n   dkron leave \n   dkron raft \n   dkron raft list-peers \n   dkron raft remove-peer \n   dkron version \n    Access Control \n   Authentication \n   Commercial FAQ \n   Commercial Support \n   Configuration \n   Cross region failover \n   Encryption \n   Executors \n  AWS ECS Executor \n   Docker executor \n    Processors \n  Elasticsearch processor \n   Email processor \n   Slack processor \n    "
},
{
	"uri": "/v2.0/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": " Pro CLI \n  dkron \n   dkron agent \n   dkron doc \n   dkron keygen \n   dkron leave \n   dkron raft \n   dkron raft list-peers \n   dkron raft remove-peer \n   dkron version \n    Access Control \n   Authentication \n   Commercial FAQ \n   Commercial Support \n   Configuration \n   Cross region failover \n   Encryption \n   Executors \n  AWS ECS Executor \n   Docker executor \n    Processors \n  Elasticsearch processor \n   Email processor \n   Slack processor \n    "
},
{
	"uri": "/v1.2/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": " Quick start\nGetting started Dkron Pro provides a clustering backend store out of the box based on etcd. To configure the storage a sample etcd.conf.yaml file is provided in /etc/dkron path. Editing the file, allows to configure several options for the embedded store. The location of the store configuration can be set in the command line or in the dkron config file /etc/dkron/dkron.yml using etcd-config-file-path parameter. Starting a single node Works out of the box, good for non HA installations.\n  Pro CLI\ndkron dkron Professional distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  Authorization\nDkron Pro has the ability to be configured to use HTTP basic auth. Authentication can be set using these parameters in the dkron config file: # dkron.yml username: dkron_admin password: adminpassword This will enable auth on the WebUI and for the API.\n  Clustering\nConfigure a cluster First follow the Dkron clustering guide then you can continue with this guide. The embedded store also needs to know its peers, it needs its own configuration as in the following example: # etcd.conf.yaml # Initial cluster configuration for bootstrapping. initial-cluster: dkron1=https://10.19.3.9:2380,dkron2=https://10.19.4.64:2380,dkron3=https://10.19.7.215:2380 With this configuration Dkron Pro should start in cluster mode with embedded storage. For a more in detail guide of clustering with etcd follow this guide: https://github.\n  Commercial FAQ\nWhat is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers. Is there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you. Can I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price. What is the license? See COMM-LICENSE.\n  Commercial Support\nDkron offers only community support. Dkro Pro offers priority support via email. Priority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not the application or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n  Configuration\nConfiguration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters. Command line options --etcd-config-file-path - Etcd node config --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates   Embedded storage\nDkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started. This ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron.\n  Encryption\nSSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also if client auth is enabled, only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron\u0026rsquo;s etcd server. This ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\n  Executors\n\n  Processors\nElasticsearch processor The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node. The output logs of the job execution will be stored in the indicated ES instace. Configuration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } } Email processor\n  "
},
{
	"uri": "/products/",
	"title": "Products",
	"tags": [],
	"description": "",
	"content": " Dkron Pro\nDkron Pro Improved security, features and reliability for your scheduled jobs Buy Get additional features and commercial support from the creator of Dkron Key features Security Pro has enhanced security using industry standard SSL encryption for communication between all components of the application, the embedded storage engine and nodes. You can also enable basic authentication to restrict access to the WebUI and the API.\n  "
},
{
	"uri": "/v2.0/products/",
	"title": "Products",
	"tags": [],
	"description": "",
	"content": " Dkron Pro\nDkron Pro Improved security, features and reliability for your scheduled jobs Buy Get additional features and commercial support from the creator of Dkron Key features Security Pro has enhanced security using industry standard SSL encryption for communication between all components of the application, the embedded storage engine and nodes. You can also enable basic authentication to restrict access to the WebUI and the API.\n  "
},
{
	"uri": "/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": "Dkron - Distributed, fault tolerant job scheduling system Welcome to the Dkron documentation! This is the reference guide on how to use Dkron. If you want a getting started guide refer to the getting started guide.\nWhat is Dkron Dkron is a distributed system to run scheduled jobs against a server or a group of servers of any size. One of the machines is the leader and the others will be followers. If the leader fails or becomes unreachable, any other one will take over and reschedule all jobs to keep the system healthy.\nIn case the old leader becomes alive again, it\u0026rsquo;ll become a follower.\nDkron is a distributed cron drop-in replacement, easy to setup and fault tolerant with focus in:\n Easy: Easy to use with a great UI Reliable: Completely fault tolerant Highly scalable: Able to handle high volumes of scheduled jobs and thousands of nodes  Dkron is written in Go and leverages the power of distributed key value stores and Serf for providing fault tolerance, reliability and scalability while remaining simple and easily installable.\nDkron is inspired by the google whitepaper Reliable Cron across the Planet\nDkron runs on Linux, OSX and Windows. It can be used to run scheduled commands on a server cluster using any combination of servers for each job. It has no single points of failure due to the use of the fault tolerant distributed databases and can work at large scale thanks to the efficient and lightweight gossip protocol.\nDkron uses the efficient and lightweight gossip protocol underneath to communicate with nodes. Failure notification and task handling are run efficiently across an entire cluster of any size.\nWeb UI ![](/img/screenshot1.png)  Dkron design Dkron is designed to solve one problem well, executing commands in given intervals. Following the unix philosophy of doing one thing and doing it well (like the battle-tested cron) but with the given addition of being designed for the cloud era, removing single points of failure in environments where scheduled jobs are needed to be run in multiple servers.\n"
},
{
	"uri": "/v1.2/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": "Dkron - Distributed, fault tolerant job scheduling system Welcome to the Dkron documentation! This is the reference guide on how to use Dkron. If you want a getting started guide refer to the getting started guide.\nWhat is Dkron Dkron is a distributed system to run scheduled jobs against a server or a group of servers of any size. One of the machines is the leader and the others will be followers. If the leader fails or becomes unreachable, any other one will take over and reschedule all jobs to keep the system healthy.\nIn case the old leader becomes alive again, it\u0026rsquo;ll become a follower.\nDkron is a distributed cron drop-in replacement, easy to setup and fault tolerant with focus in:\n Easy: Easy to use with a great UI Reliable: Completely fault tolerant Highly scalable: Able to handle high volumes of scheduled jobs and thousands of nodes  Dkron is written in Go and leverages the power of distributed key value stores and Serf for providing fault tolerance, reliability and scalability while remaining simple and easily installable.\nDkron is inspired by the google whitepaper Reliable Cron across the Planet\nDkron runs on Linux, OSX and Windows. It can be used to run scheduled commands on a server cluster using any combination of servers for each job. It has no single points of failure due to the use of the fault tolerant distributed databases and can work at large scale thanks to the efficient and lightweight gossip protocol.\nDkron uses the efficient and lightweight gossip protocol underneath to communicate with nodes. Failure notification and task handling are run efficiently across an entire cluster of any size.\nWeb UI ![](/img/screenshot1.png)  Dkron design Dkron is designed to solve one problem well, executing commands in given intervals. Following the unix philosophy of doing one thing and doing it well (like the battle-tested cron) but with the given addition of being designed for the cloud era, removing single points of failure in environments where scheduled jobs are needed to be run in multiple servers.\n"
},
{
	"uri": "/v2.0/intro/",
	"title": "Intro",
	"tags": [],
	"description": "",
	"content": "Dkron - Distributed, fault tolerant job scheduling system Welcome to the Dkron documentation! This is the reference guide on how to use Dkron. If you want a getting started guide refer to the getting started guide.\nWhat is Dkron Dkron is a distributed system to run scheduled jobs against a server or a group of servers of any size. One of the machines is the leader and the others will be followers. If the leader fails or becomes unreachable, any other one will take over and reschedule all jobs to keep the system healthy.\nIn case the old leader becomes alive again, it\u0026rsquo;ll become a follower.\nDkron is a distributed cron drop-in replacement, easy to setup and fault tolerant with focus in:\n Easy: Easy to use with a great UI Reliable: Completely fault tolerant Highly scalable: Able to handle high volumes of scheduled jobs and thousands of nodes  Dkron is written in Go and leverages the power of distributed key value stores and Serf for providing fault tolerance, reliability and scalability while remaining simple and easily installable.\nDkron is inspired by the google whitepaper Reliable Cron across the Planet\nDkron runs on Linux, OSX and Windows. It can be used to run scheduled commands on a server cluster using any combination of servers for each job. It has no single points of failure due to the use of the fault tolerant distributed databases and can work at large scale thanks to the efficient and lightweight gossip protocol.\nDkron uses the efficient and lightweight gossip protocol underneath to communicate with nodes. Failure notification and task handling are run efficiently across an entire cluster of any size.\nWeb UI ![](/img/screenshot1.png)  Dkron design Dkron is designed to solve one problem well, executing commands in given intervals. Following the unix philosophy of doing one thing and doing it well (like the battle-tested cron) but with the given addition of being designed for the cloud era, removing single points of failure in environments where scheduled jobs are needed to be run in multiple servers.\n"
},
{
	"uri": "/cli/",
	"title": "CLI",
	"tags": [],
	"description": "",
	"content": " dkron\ndkron Open source distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file path -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  dkron agent\ndkron agent Start a dkron agent Synopsis Start a dkron agent that schedules jobs, listens for executions and runs executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism.\n  dkron doc\ndkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 15-May-2020   dkron keygen\ndkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 15-May-2020   dkron leave\ndkron leave Force an agent to leave the cluster Synopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. dkron leave [flags] Options -h, --help help for leave --rpc-addr string gRPC address of the agent (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 15-May-2020   dkron raft\ndkron raft Command to perform some raft operations Synopsis Command to perform some raft operations Options -h, --help help for raft --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system dkron raft list-peers\t- Command to list raft peers dkron raft remove-peer\t- Command to list raft peers Auto generated by spf13/cobra on 15-May-2020   dkron raft list-peers\ndkron raft list-peers Command to list raft peers Synopsis Command to list raft peers dkron raft list-peers [flags] Options -h, --help help for list-peers Options inherited from parent commands --config string config file path --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) SEE ALSO dkron raft\t- Command to perform some raft operations Auto generated by spf13/cobra on 15-May-2020   dkron raft remove-peer\ndkron raft remove-peer Command to list raft peers Synopsis Command to list raft peers dkron raft remove-peer [flags] Options -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands --config string config file path --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) SEE ALSO dkron raft\t- Command to perform some raft operations Auto generated by spf13/cobra on 15-May-2020   dkron version\ndkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 15-May-2020   "
},
{
	"uri": "/pro/cli/",
	"title": "Pro CLI",
	"tags": [],
	"description": "",
	"content": " dkron\ndkron Professional distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  dkron agent\ndkron agent Start a dkron agent Synopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --auto-tls Client TLS using generated certificates (default true) --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism.\n  dkron doc\ndkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.\n  dkron keygen\ndkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron\t- Professional distributed job scheduling system Auto generated by spf13/cobra on 15-May-2020   dkron leave\ndkron leave Force an agent to leave the cluster Synopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. If this is a server and has the scheduler started stop it, ignoring if this server was participating in leader election or not (local storage).\n  dkron raft\ndkron raft Command to perform some raft operations Synopsis Command to perform some raft operations Options --cert-file string Path to the client server TLS cert file -h, --help help for raft --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.\n  dkron raft list-peers\ndkron raft list-peers Command to list raft peers Synopsis Command to list raft peers dkron raft list-peers [flags] Options -h, --help help for list-peers Options inherited from parent commands --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file SEE ALSO dkron raft\t- Command to perform some raft operations Auto generated by spf13/cobra on 15-May-2020   dkron raft remove-peer\ndkron raft remove-peer Command to list raft peers Synopsis Command to list raft peers dkron raft remove-peer [flags] Options -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent.\n  dkron version\ndkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron\t- Professional distributed job scheduling system Auto generated by spf13/cobra on 15-May-2020   "
},
{
	"uri": "/v2.0/cli/",
	"title": "CLI",
	"tags": [],
	"description": "",
	"content": " dkron\ndkron Open source distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file path -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  dkron agent\ndkron agent Start a dkron agent Synopsis Start a dkron agent that schedules jobs, listens for executions and runs executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism.\n  dkron doc\ndkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 10-Oct-2019   dkron keygen\ndkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 10-Oct-2019   dkron leave\ndkron leave Force an agent to leave the cluster Synopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. dkron leave [flags] Options -h, --help help for leave --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 10-Oct-2019   dkron raft\ndkron raft Command to perform some raft operations Synopsis Command to perform some raft operations Options -h, --help help for raft --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system dkron raft list-peers\t- Command to list raft peers dkron raft remove-peer\t- Command to list raft peers Auto generated by spf13/cobra on 10-Oct-2019   dkron raft list-peers\ndkron raft list-peers Command to list raft peers Synopsis Command to list raft peers dkron raft list-peers [flags] Options -h, --help help for list-peers Options inherited from parent commands --config string config file path --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) SEE ALSO dkron raft\t- Command to perform some raft operations Auto generated by spf13/cobra on 10-Oct-2019   dkron raft remove-peer\ndkron raft remove-peer Command to list raft peers Synopsis Command to list raft peers dkron raft remove-peer [flags] Options -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands --config string config file path --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) SEE ALSO dkron raft\t- Command to perform some raft operations Auto generated by spf13/cobra on 10-Oct-2019   dkron version\ndkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 10-Oct-2019   "
},
{
	"uri": "/v2.0/pro/cli/",
	"title": "Pro CLI",
	"tags": [],
	"description": "",
	"content": " dkron\ndkron Professional distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  dkron agent\ndkron agent Start a dkron agent Synopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --auto-tls Client TLS using generated certificates (default true) --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism.\n  dkron doc\ndkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.\n  dkron keygen\ndkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron\t- Professional distributed job scheduling system Auto generated by spf13/cobra on 26-Aug-2019   dkron leave\ndkron leave Force an agent to leave the cluster Synopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. If this is a server and has the scheduler started stop it, ignoring if this server was participating in leader election or not (local storage).\n  dkron raft\ndkron raft Command to perform some raft operations Synopsis Command to perform some raft operations Options --cert-file string Path to the client server TLS cert file -h, --help help for raft --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.\n  dkron raft list-peers\ndkron raft list-peers Command to list raft peers Synopsis Command to list raft peers dkron raft list-peers [flags] Options -h, --help help for list-peers Options inherited from parent commands --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file SEE ALSO dkron raft\t- Command to perform some raft operations Auto generated by spf13/cobra on 26-Aug-2019   dkron raft remove-peer\ndkron raft remove-peer Command to list raft peers Synopsis Command to list raft peers dkron raft remove-peer [flags] Options -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.\n  dkron version\ndkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron\t- Professional distributed job scheduling system Auto generated by spf13/cobra on 26-Aug-2019   "
},
{
	"uri": "/v1.2/cli/",
	"title": "CLI",
	"tags": [],
	"description": "",
	"content": " dkron\ndkron Open source distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file path -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  dkron agent\ndkron agent Start a dkron agent Synopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised --advertise-rpc-port int Use the value of rpc-port by default --backend string Store backend (etcd|etcdv3|consul|zk|redis|boltdb|dynamodb) (default \u0026quot;boltdb\u0026quot;) --backend-machine strings Store backend machines addresses (default [.\n  dkron doc\ndkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 22-Mar-2019   dkron keygen\ndkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 22-Mar-2019   dkron leave\ndkron leave Force an agent to leave the cluster Synopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. If this is a server and has the scheduler started stop it, ignoring if this server was participating in leader election or not (local storage).\n  dkron version\ndkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file path SEE ALSO dkron\t- Open source distributed job scheduling system Auto generated by spf13/cobra on 22-Mar-2019   "
},
{
	"uri": "/v1.2/pro/cli/",
	"title": "Pro CLI",
	"tags": [],
	"description": "",
	"content": " dkron\ndkron Professional distributed job scheduling system Synopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention. Options --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI.\n  dkron agent\ndkron agent Start a dkron agent Synopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI. dkron agent [flags] Options --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. --advertise-rpc-port int Use the value of rpc-port by default. --auto-tls Client TLS using generated certificates (default true) --backend string store backend (default \u0026quot;boltdb\u0026quot;) --backend-machine strings store backend machines addresses (default [.\n  dkron doc\ndkron doc Generate Markdown documentation for the Dkron CLI. Synopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo. dkron doc [flags] Options --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.\n  dkron keygen\ndkron keygen Generates a new encryption key Synopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects. dkron keygen [flags] Options -h, --help help for keygen Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron\t- Professional distributed job scheduling system Auto generated by spf13/cobra on 21-Jan-2019   dkron version\ndkron version Show version Synopsis Show the version dkron version [flags] Options -h, --help help for version Options inherited from parent commands --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO dkron\t- Professional distributed job scheduling system Auto generated by spf13/cobra on 21-Jan-2019   "
},
{
	"uri": "/usage/plugins/develop/",
	"title": "Developing plugins",
	"tags": [],
	"description": "",
	"content": "Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation.\n Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.\nNote: A common pitfall is not properly setting up a $GOPATH. This can lead to strange errors. You can read more about this here to familiarize yourself.\nCreate a new Go project somewhere in your $GOPATH. If you\u0026rsquo;re a GitHub user, we recommend creating the project in the directory $GOPATH/src/github.com/USERNAME/dkron-NAME-TYPE, where USERNAME is your GitHub username and NAME is the name of the plugin you\u0026rsquo;re developing. This structure is what Go expects and simplifies things down the road.\nWith the directory made, create a main.go file. This project will be a binary so the package is \u0026ldquo;main\u0026rdquo;:\npackage main import ( \u0026#34;github.com/distribworks/dkron/v3/plugin\u0026#34; ) func main() { plugin.Serve(\u0026amp;plugin.ServeOpts{ Processor: new(MyPlugin), }) } And that\u0026rsquo;s basically it! You\u0026rsquo;ll have to change the argument given to plugin.Serve to be your actual plugin, but that is the only change you\u0026rsquo;ll have to make. The argument should be a structure implementing one of the plugin interfaces (depending on what sort of plugin you\u0026rsquo;re creating).\nDkron plugins must follow a very specific naming convention of dkron-TYPE-NAME. For example, dkron-processor-files, which tells Dkron that the plugin is a processor that can be referenced as \u0026ldquo;files\u0026rdquo;.\n"
},
{
	"uri": "/v1.2/usage/plugins/develop/",
	"title": "Developing plugins",
	"tags": [],
	"description": "",
	"content": "Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.\nNote: A common pitfall is not properly setting up a $GOPATH. This can lead to strange errors. You can read more about this here to familiarize yourself.\nCreate a new Go project somewhere in your $GOPATH. If you\u0026rsquo;re a GitHub user, we recommend creating the project in the directory $GOPATH/src/github.com/USERNAME/dkron-NAME-TYPE, where USERNAME is your GitHub username and NAME is the name of the plugin you\u0026rsquo;re developing. This structure is what Go expects and simplifies things down the road.\nWith the directory made, create a main.go file. This project will be a binary so the package is \u0026ldquo;main\u0026rdquo;:\npackage main import ( \u0026#34;github.com/distribworks/dkron/plugin\u0026#34; ) func main() { plugin.Serve(\u0026amp;plugin.ServeOpts{ Processor: new(MyPlugin), }) } And that\u0026rsquo;s basically it! You\u0026rsquo;ll have to change the argument given to plugin.Serve to be your actual plugin, but that is the only change you\u0026rsquo;ll have to make. The argument should be a structure implementing one of the plugin interfaces (depending on what sort of plugin you\u0026rsquo;re creating).\nDkron plugins must follow a very specific naming convention of dkron-TYPE-NAME. For example, dkron-processor-files, which tells Dkron that the plugin is a processor that can be referenced as \u0026ldquo;files\u0026rdquo;.\n"
},
{
	"uri": "/v2.0/usage/plugins/develop/",
	"title": "Developing plugins",
	"tags": [],
	"description": "",
	"content": "Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.\nNote: A common pitfall is not properly setting up a $GOPATH. This can lead to strange errors. You can read more about this here to familiarize yourself.\nCreate a new Go project somewhere in your $GOPATH. If you\u0026rsquo;re a GitHub user, we recommend creating the project in the directory $GOPATH/src/github.com/USERNAME/dkron-NAME-TYPE, where USERNAME is your GitHub username and NAME is the name of the plugin you\u0026rsquo;re developing. This structure is what Go expects and simplifies things down the road.\nWith the directory made, create a main.go file. This project will be a binary so the package is \u0026ldquo;main\u0026rdquo;:\npackage main import ( \u0026#34;github.com/distribworks/dkron/v3/plugin\u0026#34; ) func main() { plugin.Serve(\u0026amp;plugin.ServeOpts{ Processor: new(MyPlugin), }) } And that\u0026rsquo;s basically it! You\u0026rsquo;ll have to change the argument given to plugin.Serve to be your actual plugin, but that is the only change you\u0026rsquo;ll have to make. The argument should be a structure implementing one of the plugin interfaces (depending on what sort of plugin you\u0026rsquo;re creating).\nDkron plugins must follow a very specific naming convention of dkron-TYPE-NAME. For example, dkron-processor-files, which tells Dkron that the plugin is a processor that can be referenced as \u0026ldquo;files\u0026rdquo;.\n"
},
{
	"uri": "/api/",
	"title": "API",
	"tags": [],
	"description": "",
	"content": " body { line-height: 1.7; } .swagger-ui .info .title small pre { background-color: inherit; padding: inherit; } .swagger-ui .scheme-container { display: none !important; }      window.onload = function () { // Begin Swagger UI call region const ui = SwaggerUIBundle({ url: \"https://dkron.io/swagger.yaml\", dom_id: '#swagger-ui', deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], layout: \"BaseLayout\" }) // End Swagger UI call region window.ui = ui }  "
},
{
	"uri": "/v1.2/api/",
	"title": "API",
	"tags": [],
	"description": "",
	"content": " body { line-height: 1.7; } .swagger-ui .info .title small pre { background-color: inherit; padding: inherit; } .swagger-ui .scheme-container { display: none !important; }      window.onload = function () { // Begin Swagger UI call region const ui = SwaggerUIBundle({ url: \"/v1.2/swagger.yaml\", dom_id: '#swagger-ui', deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], layout: \"BaseLayout\" }) // End Swagger UI call region window.ui = ui }  "
},
{
	"uri": "/v2.0/api/",
	"title": "API",
	"tags": [],
	"description": "",
	"content": " body { line-height: 1.7; } .swagger-ui .info .title small pre { background-color: inherit; padding: inherit; } .swagger-ui .scheme-container { display: none !important; }      window.onload = function () { // Begin Swagger UI call region const ui = SwaggerUIBundle({ url: \"/v2.0/swagger.yaml\", dom_id: '#swagger-ui', deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], layout: \"BaseLayout\" }) // End Swagger UI call region window.ui = ui }  "
},
{
	"uri": "/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": "dkron Open source distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file path -h, --help help for dkron SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron leave\t- Force an agent to leave the cluster dkron raft\t- Command to perform some raft operations dkron version\t- Show version  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": "dkron Professional distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron leave\t- Force an agent to leave the cluster dkron raft\t- Command to perform some raft operations dkron version\t- Show version  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": "dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedules jobs, listens for executions and runs executors. It also runs a web UI.\ndkron agent [flags] Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism. This should be specified in IP format, and can be used to easily bind all network services to the same address. The value supports go-sockaddr/template format. (default \u0026quot;{{ GetPrivateIP }}:8946\u0026quot;) --bootstrap-expect int Provides the number of expected servers in the datacenter. Either this value should not be provided or the value must agree with other servers in the cluster. When provided, Dkron waits until the specified number of servers are available and then bootstraps the cluster. This allows an initial leader to be elected automatically. This flag requires server mode. --data-dir string Specifies the directory to use for server-specific data, including the replicated log. By default, this is the top-level data-dir, like [/var/lib/dkron] (default \u0026quot;dkron.data\u0026quot;) --datacenter string Specifies the data center of the local agent. All members of a datacenter should share a local LAN connection. (default \u0026quot;dc1\u0026quot;) --dog-statsd-addr string DataDog Agent address --dog-statsd-tags strings Datadog tags, specified as key:value --enable-prometheus Enable serving prometheus metrics --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. The value supports go-sockaddr/template format. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times --log-level string Log level (debug|info|warn|error|fatal|panic) (default \u0026quot;info\u0026quot;) --mail-from string From email address to use --mail-host string Mail server host address to use for notifications --mail-password string Mail server password to use --mail-payload string Notification mail payload --mail-port uint16 Mail server port --mail-subject-prefix string Notification mail subject prefix (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication --node-name string Name of this node. Must be unique in the cluster (default \u0026quot;pris.local\u0026quot;) --profile string Profile is used to control the timing profiles used (default \u0026quot;lan\u0026quot;) --raft-multiplier int An integer multiplier used by servers to scale key Raft timing parameters. Omitting this value or setting it to 0 uses default timing described below. Lower values are used to tighten timing and increase sensitivity while higher values relax timings and reduce sensitivity. Tuning this affects the time it takes to detect leader failures and to perform leader elections, at the expense of requiring more network and CPU resources for better performance. By default, Dkron will use a lower-performance timing that's suitable for minimal Dkron servers, currently equivalent to setting this to a value of 5 (this default may be changed in future versions of Dkron, depending if the target minimum server profile changes). Setting this to a value of 1 will configure Raft to its highest-performance mode is recommended for production Dkron servers. The maximum allowed value is 10. (default 1) --region string Specifies the region the Dkron agent is a member of. A region typically maps to a geographic region, for example us, with potentially multiple zones, which map to datacenters such as us-west and us-east (default \u0026quot;global\u0026quot;) --retry-interval string Time to wait between join attempts. (default \u0026quot;30s\u0026quot;) --retry-join strings Address of an agent to join at start time with retries enabled. Can be specified multiple times. --retry-max int Maximum number of join attempts. Defaults to 0, which will retry indefinitely. --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address (default 6868) --serf-reconnect-timeout string This is the amount of time to attempt to reconnect to a failed node before giving up and considering it completely gone. In Kubernetes, you might need this to about 5s, because there is no reason to try reconnects for default 24h value. Also Raft behaves oddly if node is not reaped and returned with same ID, but different IP. Format there: https://golang.org/pkg/time/#ParseDuration (default \u0026quot;24h\u0026quot;) --server This node is running in server mode --statsd-addr string Statsd address --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node, specified as key=value --webhook-headers strings Headers to use when calling the webhook URL. Can be specified multiple times --webhook-payload string Body of the POST request to send on webhook call --webhook-url string Webhook url to call for notifications Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": "dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI.\ndkron agent [flags] Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --auto-tls Client TLS using generated certificates (default true) --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism. This should be specified in IP format, and can be used to easily bind all network services to the same address. The value supports go-sockaddr/template format. (default \u0026quot;{{ GetPrivateIP }}:8946\u0026quot;) --bootstrap-expect int Provides the number of expected servers in the datacenter. Either this value should not be provided or the value must agree with other servers in the cluster. When provided, Dkron waits until the specified number of servers are available and then bootstraps the cluster. This allows an initial leader to be elected automatically. This flag requires server mode. --cert-file string Path to the client server TLS cert file --client-cert-auth Enable client cert authentication --client-crl-file string Path to the client certificate revocation list file --data-dir string Specifies the directory to use for server-specific data, including the replicated log. By default, this is the top-level data-dir, like [/var/lib/dkron] (default \u0026quot;dkron.data\u0026quot;) --datacenter string Specifies the data center of the local agent. All members of a datacenter should share a local LAN connection. (default \u0026quot;dc1\u0026quot;) --disable-http-tls Disable TLS for HTTP WebUI/API regardless of TLS configuration --dog-statsd-addr string DataDog Agent address --dog-statsd-tags strings Datadog tags, specified as key:value --enable-prometheus Enable serving prometheus metrics --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key --federation-mode string Federation mode between clusters in different regions (default \u0026quot;active\u0026quot;) -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. The value supports go-sockaddr/template format. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times --key-file string Path to the client server TLS key file --log-level string Log level (debug|info|warn|error|fatal|panic) (default \u0026quot;info\u0026quot;) --mail-from string From email address to use --mail-host string Mail server host address to use for notifications --mail-password string Mail server password to use --mail-payload string Notification mail payload --mail-port uint16 Mail server port --mail-subject-prefix string Notification mail subject prefix (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication --node-name string Name of this node. Must be unique in the cluster (default \u0026quot;pris.local\u0026quot;) --password string authentication password --profile string Profile is used to control the timing profiles used (default \u0026quot;lan\u0026quot;) --raft-multiplier int An integer multiplier used by servers to scale key Raft timing parameters. Omitting this value or setting it to 0 uses default timing described below. Lower values are used to tighten timing and increase sensitivity while higher values relax timings and reduce sensitivity. Tuning this affects the time it takes to detect leader failures and to perform leader elections, at the expense of requiring more network and CPU resources for better performance. By default, Dkron will use a lower-performance timing that's suitable for minimal Dkron servers, currently equivalent to setting this to a value of 5 (this default may be changed in future versions of Dkron, depending if the target minimum server profile changes). Setting this to a value of 1 will configure Raft to its highest-performance mode is recommended for production Dkron servers. The maximum allowed value is 10. (default 1) --region string Specifies the region the Dkron agent is a member of. A region typically maps to a geographic region, for example us, with potentially multiple zones, which map to datacenters such as us-west and us-east (default \u0026quot;global\u0026quot;) --retry-interval string Time to wait between join attempts. (default \u0026quot;30s\u0026quot;) --retry-join strings Address of an agent to join at start time with retries enabled. Can be specified multiple times. --retry-max int Maximum number of join attempts. Defaults to 0, which will retry indefinitely. --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address (default 6868) --serf-reconnect-timeout string This is the amount of time to attempt to reconnect to a failed node before giving up and considering it completely gone. In Kubernetes, you might need this to about 5s, because there is no reason to try reconnects for default 24h value. Also Raft behaves oddly if node is not reaped and returned with same ID, but different IP. Format there: https://golang.org/pkg/time/#ParseDuration (default \u0026quot;24h\u0026quot;) --server This node is running in server mode --statsd-addr string Statsd address --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node, specified as key=value --trusted-ca-file string Path to the client server TLS trusted CA cert file --username string authentication username --webhook-headers strings Headers to use when calling the webhook URL. Can be specified multiple times --webhook-payload string Body of the POST request to send on webhook call --webhook-url string Webhook url to call for notifications Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": "dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags] Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": "dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags] Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": "dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags] Options  -h, --help help for keygen Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": "dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags] Options  -h, --help help for keygen Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_leave/",
	"title": "dkron leave",
	"tags": [],
	"description": "",
	"content": "dkron leave Force an agent to leave the cluster\nSynopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler.\ndkron leave [flags] Options  -h, --help help for leave --rpc-addr string gRPC address of the agent (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_leave/",
	"title": "dkron leave",
	"tags": [],
	"description": "",
	"content": "dkron leave Force an agent to leave the cluster\nSynopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. If this is a server and has the scheduler started stop it, ignoring if this server was participating in leader election or not (local storage). Then actually leave the cluster.\ndkron leave [flags] Options  --cert-file string Path to the client server TLS cert file -h, --help help for leave --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_raft/",
	"title": "dkron raft",
	"tags": [],
	"description": "",
	"content": "dkron raft Command to perform some raft operations\nSynopsis Command to perform some raft operations\nOptions  -h, --help help for raft --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system dkron raft list-peers\t- Command to list raft peers dkron raft remove-peer\t- Command to list raft peers  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_raft/",
	"title": "dkron raft",
	"tags": [],
	"description": "",
	"content": "dkron raft Command to perform some raft operations\nSynopsis Command to perform some raft operations\nOptions  --cert-file string Path to the client server TLS cert file -h, --help help for raft --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system dkron raft list-peers\t- Command to list raft peers dkron raft remove-peer\t- Command to list raft peers  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_raft_list-peers/",
	"title": "dkron raft list-peers",
	"tags": [],
	"description": "",
	"content": "dkron raft list-peers Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft list-peers [flags] Options  -h, --help help for list-peers Options inherited from parent commands  --config string config file path --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_raft_list-peers/",
	"title": "dkron raft list-peers",
	"tags": [],
	"description": "",
	"content": "dkron raft list-peers Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft list-peers [flags] Options  -h, --help help for list-peers Options inherited from parent commands  --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_raft_remove-peer/",
	"title": "dkron raft remove-peer",
	"tags": [],
	"description": "",
	"content": "dkron raft remove-peer Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft remove-peer [flags] Options  -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands  --config string config file path --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_raft_remove-peer/",
	"title": "dkron raft remove-peer",
	"tags": [],
	"description": "",
	"content": "dkron raft remove-peer Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft remove-peer [flags] Options  -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands  --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent. (default \u0026quot;{{ GetPrivateIP }}:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": "dkron version Show version\nSynopsis Show the version\ndkron version [flags] Options  -h, --help help for version Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/pro/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": "dkron version Show version\nSynopsis Show the version\ndkron version [flags] Options  -h, --help help for version Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 15-May-2020 "
},
{
	"uri": "/v2.0/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": "dkron Open source distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file path -h, --help help for dkron SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron leave\t- Force an agent to leave the cluster dkron raft\t- Command to perform some raft operations dkron version\t- Show version  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": "dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedules jobs, listens for executions and runs executors. It also runs a web UI.\ndkron agent [flags] Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism. This should be specified in IP format, and can be used to easily bind all network services to the same address. The value supports go-sockaddr/template format. (default \u0026quot;0.0.0.0:8946\u0026quot;) --bootstrap-expect int Provides the number of expected servers in the datacenter. Either this value should not be provided or the value must agree with other servers in the cluster. When provided, Dkron waits until the specified number of servers are available and then bootstraps the cluster. This allows an initial leader to be elected automatically. This flag requires server mode. --data-dir string Specifies the directory to use for server-specific data, including the replicated log. By default, this is the top-level data-dir, like [/var/lib/dkron] (default \u0026quot;dkron.data\u0026quot;) --datacenter string Specifies the data center of the local agent. All members of a datacenter should share a local LAN connection. (default \u0026quot;dc1\u0026quot;) --dog-statsd-addr string DataDog Agent address --dog-statsd-tags strings Datadog tags, specified as key:value --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. The value supports go-sockaddr/template format. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times --log-level string Log level (debug|info|warn|error|fatal|panic) (default \u0026quot;info\u0026quot;) --mail-from string From email address to use --mail-host string Mail server host address to use for notifications --mail-password string Mail server password to use --mail-payload string Notification mail payload --mail-port uint16 Mail server port --mail-subject-prefix string Notification mail subject prefix (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication --node-name string Name of this node. Must be unique in the cluster (default \u0026quot;pris.local\u0026quot;) --profile string Profile is used to control the timing profiles used (default \u0026quot;lan\u0026quot;) --raft-multiplier int An integer multiplier used by servers to scale key Raft timing parameters. Omitting this value or setting it to 0 uses default timing described below. Lower values are used to tighten timing and increase sensitivity while higher values relax timings and reduce sensitivity. Tuning this affects the time it takes to detect leader failures and to perform leader elections, at the expense of requiring more network and CPU resources for better performance. By default, Dkron will use a lower-performance timing that's suitable for minimal Dkron servers, currently equivalent to setting this to a value of 5 (this default may be changed in future versions of Dkron, depending if the target minimum server profile changes). Setting this to a value of 1 will configure Raft to its highest-performance mode is recommended for production Dkron servers. The maximum allowed value is 10. (default 1) --region string Specifies the region the Dkron agent is a member of. A region typically maps to a geographic region, for example us, with potentially multiple zones, which map to datacenters such as us-west and us-east (default \u0026quot;global\u0026quot;) --retry-interval string Time to wait between join attempts. (default \u0026quot;30s\u0026quot;) --retry-join strings Address of an agent to join at start time with retries enabled. Can be specified multiple times. --retry-max int Maximum number of join attempts. Defaults to 0, which will retry indefinitely. --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address (default 6868) --server This node is running in server mode --statsd-addr string Statsd address --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node, specified as key=value --webhook-header strings Headers to use when calling the webhook URL. Can be specified multiple times --webhook-payload string Body of the POST request to send on webhook call --webhook-url string Webhook url to call for notifications Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": "dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags] Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": "dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags] Options  -h, --help help for keygen Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_leave/",
	"title": "dkron leave",
	"tags": [],
	"description": "",
	"content": "dkron leave Force an agent to leave the cluster\nSynopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler.\ndkron leave [flags] Options  -h, --help help for leave --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_raft/",
	"title": "dkron raft",
	"tags": [],
	"description": "",
	"content": "dkron raft Command to perform some raft operations\nSynopsis Command to perform some raft operations\nOptions  -h, --help help for raft --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system dkron raft list-peers\t- Command to list raft peers dkron raft remove-peer\t- Command to list raft peers  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_raft_list-peers/",
	"title": "dkron raft list-peers",
	"tags": [],
	"description": "",
	"content": "dkron raft list-peers Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft list-peers [flags] Options  -h, --help help for list-peers Options inherited from parent commands  --config string config file path --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_raft_remove-peer/",
	"title": "dkron raft remove-peer",
	"tags": [],
	"description": "",
	"content": "dkron raft remove-peer Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft remove-peer [flags] Options  -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands  --config string config file path --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": "dkron version Show version\nSynopsis Show the version\ndkron version [flags] Options  -h, --help help for version Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 10-Oct-2019 "
},
{
	"uri": "/v2.0/",
	"title": "V2.0s",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/2.0/pro/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": "dkron Professional distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron leave\t- Force an agent to leave the cluster dkron raft\t- Command to perform some raft operations dkron version\t- Show version  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": "dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI.\ndkron agent [flags] Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. The value supports go-sockaddr/template format. --advertise-rpc-port int Use the value of rpc-port by default --auto-tls Client TLS using generated certificates (default true) --bind-addr string Specifies which address the agent should bind to for network services, including the internal gossip protocol and RPC mechanism. This should be specified in IP format, and can be used to easily bind all network services to the same address. The value supports go-sockaddr/template format. (default \u0026quot;0.0.0.0:8946\u0026quot;) --bootstrap-expect int Provides the number of expected servers in the datacenter. Either this value should not be provided or the value must agree with other servers in the cluster. When provided, Dkron waits until the specified number of servers are available and then bootstraps the cluster. This allows an initial leader to be elected automatically. This flag requires server mode. --cert-file string Path to the client server TLS cert file --client-cert-auth Enable client cert authentication --client-crl-file string Path to the client certificate revocation list file --data-dir string Specifies the directory to use for server-specific data, including the replicated log. By default, this is the top-level data-dir, like [/var/lib/dkron] (default \u0026quot;dkron.data\u0026quot;) --datacenter string Specifies the data center of the local agent. All members of a datacenter should share a local LAN connection. (default \u0026quot;dc1\u0026quot;) --dog-statsd-addr string DataDog Agent address --dog-statsd-tags strings Datadog tags, specified as key:value --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key --federation-mode string Federation mode between clusters in different regions (default \u0026quot;active\u0026quot;) -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. The value supports go-sockaddr/template format. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times --key-file string Path to the client server TLS key file --log-level string Log level (debug|info|warn|error|fatal|panic) (default \u0026quot;info\u0026quot;) --mail-from string From email address to use --mail-host string Mail server host address to use for notifications --mail-password string Mail server password to use --mail-payload string Notification mail payload --mail-port uint16 Mail server port --mail-subject-prefix string Notification mail subject prefix (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication --node-name string Name of this node. Must be unique in the cluster (default \u0026quot;pris.local\u0026quot;) --password string authentication password --profile string Profile is used to control the timing profiles used (default \u0026quot;lan\u0026quot;) --region string Specifies the region the Dkron agent is a member of. A region typically maps to a geographic region, for example us, with potentially multiple zones, which map to datacenters such as us-west and us-east (default \u0026quot;global\u0026quot;) --retry-interval string Time to wait between join attempts. (default \u0026quot;30s\u0026quot;) --retry-join strings Address of an agent to join at start time with retries enabled. Can be specified multiple times. --retry-max int Maximum number of join attempts. Defaults to 0, which will retry indefinitely. --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address (default 6868) --server This node is running in server mode --statsd-addr string Statsd address --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node, specified as key=value --trusted-ca-file string Path to the client server TLS trusted CA cert file --username string authentication username --webhook-header strings Headers to use when calling the webhook URL. Can be specified multiple times --webhook-payload string Body of the POST request to send on webhook call --webhook-url string Webhook url to call for notifications Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": "dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags] Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": "dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags] Options  -h, --help help for keygen Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_leave/",
	"title": "dkron leave",
	"tags": [],
	"description": "",
	"content": "dkron leave Force an agent to leave the cluster\nSynopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. If this is a server and has the scheduler started stop it, ignoring if this server was participating in leader election or not (local storage). Then actually leave the cluster.\ndkron leave [flags] Options  --cert-file string Path to the client server TLS cert file -h, --help help for leave --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_raft/",
	"title": "dkron raft",
	"tags": [],
	"description": "",
	"content": "dkron raft Command to perform some raft operations\nSynopsis Command to perform some raft operations\nOptions  --cert-file string Path to the client server TLS cert file -h, --help help for raft --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system dkron raft list-peers\t- Command to list raft peers dkron raft remove-peer\t- Command to list raft peers  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_raft_list-peers/",
	"title": "dkron raft list-peers",
	"tags": [],
	"description": "",
	"content": "dkron raft list-peers Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft list-peers [flags] Options  -h, --help help for list-peers Options inherited from parent commands  --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_raft_remove-peer/",
	"title": "dkron raft remove-peer",
	"tags": [],
	"description": "",
	"content": "dkron raft remove-peer Command to list raft peers\nSynopsis Command to list raft peers\ndkron raft remove-peer [flags] Options  -h, --help help for remove-peer --peer-id string Remove a Dkron server with the given ID from the Raft configuration. Options inherited from parent commands  --cert-file string Path to the client server TLS cert file --config string config file (default is /etc/dkron/dkron.yml) --key-file string Path to the client server TLS key file --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) --trusted-ca-file string Path to the client server TLS trusted CA cert file SEE ALSO  dkron raft\t- Command to perform some raft operations  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/2.0/pro/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": "dkron version Show version\nSynopsis Show the version\ndkron version [flags] Options  -h, --help help for version Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 26-Aug-2019 "
},
{
	"uri": "/v1.2/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": "dkron Open source distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file path -h, --help help for dkron SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron leave\t- Force an agent to leave the cluster dkron version\t- Show version  Auto generated by spf13/cobra on 22-Mar-2019 "
},
{
	"uri": "/v1.2/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": "dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI.\ndkron agent [flags] Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised --advertise-rpc-port int Use the value of rpc-port by default --backend string Store backend (etcd|etcdv3|consul|zk|redis|boltdb|dynamodb) (default \u0026quot;boltdb\u0026quot;) --backend-machine strings Store backend machines addresses (default [./dkron.db]) --backend-password string Store backend machines password or token, only REDIS/CONSUL --bind-addr string Address to bind network listeners to (default \u0026quot;0.0.0.0:8946\u0026quot;) --dog-statsd-addr string DataDog Agent address --dog-statsd-tags strings Datadog tags, specified as key:value --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times --keyspace string The keyspace to use. A prefix under all data is stored for this instance (default \u0026quot;dkron\u0026quot;) --log-level string Log level (debug|info|warn|error|fatal|panic) (default \u0026quot;info\u0026quot;) --mail-from string From email address to use --mail-host string Mail server host address to use for notifications --mail-password string Mail server password to use --mail-payload string Notification mail payload --mail-port uint16 Mail server port --mail-subject-prefix string Notification mail subject prefix (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication --node-name string Name of this node. Must be unique in the cluster (default \u0026quot;pris.local\u0026quot;) --profile string Profile is used to control the timing profiles used (default \u0026quot;lan\u0026quot;) --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address (default 6868) --server This node is running in server mode --statsd-addr string Statsd address --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node, specified as key=value --webhook-header strings Headers to use when calling the webhook URL. Can be specified multiple times --webhook-payload string Body of the POST request to send on webhook call --webhook-url string Webhook url to call for notifications Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 22-Mar-2019 "
},
{
	"uri": "/v1.2/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": "dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags] Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 22-Mar-2019 "
},
{
	"uri": "/v1.2/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": "dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags] Options  -h, --help help for keygen Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 22-Mar-2019 "
},
{
	"uri": "/v1.2/cli/dkron_leave/",
	"title": "dkron leave",
	"tags": [],
	"description": "",
	"content": "dkron leave Force an agent to leave the cluster\nSynopsis Stop stops an agent, if the agent is a server and is running for election stop running for election, if this server was the leader this will force the cluster to elect a new leader and start a new scheduler. If this is a server and has the scheduler started stop it, ignoring if this server was participating in leader election or not (local storage). Then actually leave the cluster.\ndkron leave [flags] Options  -h, --help help for leave --rpc-addr string gRPC address of the agent (default \u0026quot;127.0.0.1:6868\u0026quot;) Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 22-Mar-2019 "
},
{
	"uri": "/v1.2/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": "dkron version Show version\nSynopsis Show the version\ndkron version [flags] Options  -h, --help help for version Options inherited from parent commands  --config string config file path SEE ALSO  dkron\t- Open source distributed job scheduling system  Auto generated by spf13/cobra on 22-Mar-2019 "
},
{
	"uri": "/v1.2/",
	"title": "V1.2s",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/v1.2/cli/dkron/",
	"title": "dkron",
	"tags": [],
	"description": "",
	"content": "dkron Professional distributed job scheduling system\nSynopsis Dkron is a system service that runs scheduled jobs at given intervals or times, just like the cron unix service but distributed in several machines in a cluster. If a machine fails (the leader), a follower will take over and keep running the scheduled jobs without human intervention.\nOptions  --config string config file (default is /etc/dkron/dkron.yml) -h, --help help for dkron SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron version\t- Show version  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/v1.2/cli/dkron_agent/",
	"title": "dkron agent",
	"tags": [],
	"description": "",
	"content": "dkron agent Start a dkron agent\nSynopsis Start a dkron agent that schedule jobs, listen for executions and run executors. It also runs a web UI.\ndkron agent [flags] Options  --advertise-addr string Address used to advertise to other nodes in the cluster. By default, the bind address is advertised. --advertise-rpc-port int Use the value of rpc-port by default. --auto-tls Client TLS using generated certificates (default true) --backend string store backend (default \u0026quot;boltdb\u0026quot;) --backend-machine strings store backend machines addresses (default [./dkron.db]) --bind-addr string Address to bind network listeners to. (default \u0026quot;0.0.0.0:8946\u0026quot;) --cert-file string Path to the client server TLS cert file --client-cert-auth Enable client cert authentication --client-crl-file string Path to the client certificate revocation list file --dog-statsd-addr string DataDog Agent address. --dog-statsd-tags strings Datadog tags, specified as key:value --encrypt string Key for encrypting network traffic. Must be a base64-encoded 16-byte key. --etcd-config-file-path string etcd node config (default \u0026quot;/etc/dkron/etcd.conf.yml\u0026quot;) -h, --help help for agent --http-addr string Address to bind the UI web server to. Only used when server. (default \u0026quot;:8080\u0026quot;) --join strings An initial agent to join with. This flag can be specified multiple times. --key-file string Path to the client server TLS key file --keyspace string The keyspace to use. A prefix under all data is stored for this instance. (default \u0026quot;dkron\u0026quot;) --log-level string Log level (debug, info, warn, error, fatal, panic), defaults to info (default \u0026quot;info\u0026quot;) --mail-from string From email address to use. --mail-host string Mail server host address to use for notifications. --mail-password string Mail server password to use. --mail-payload string Notification mail payload. --mail-port uint16 Mail server port. --mail-subject-prefix string Notification mail subject prefix. (default \u0026quot;[Dkron]\u0026quot;) --mail-username string Mail server username used for authentication. --node-name string Name of this node. Must be unique in the cluster. (default \u0026quot;pris.local\u0026quot;) --password string authentication password --profile string Profile is used to control the timing profiles used. The default if not provided is lan. (default \u0026quot;lan\u0026quot;) --rpc-port int RPC Port used to communicate with clients. Only used when server. The RPC IP Address will be the same as the bind address. (default 6868) --server This node is running in server mode. --statsd-addr string Statsd Address. --tag strings Tag can be specified multiple times to attach multiple key/value tag pairs to the given node. Specified as key=value --trusted-ca-file string Path to the client server TLS trusted CA cert file --username string authentication username --webhook-header strings Headers to use when calling the webhook URL. Can be specified multiple times. --webhook-payload string Body of the POST request to send on webhook call. --webhook-url string Webhook url to call for notifications. Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/v1.2/cli/dkron_doc/",
	"title": "dkron doc",
	"tags": [],
	"description": "",
	"content": "dkron doc Generate Markdown documentation for the Dkron CLI.\nSynopsis Generate Markdown documentation for the Dkron CLI. This command is, mostly, used to create up-to-date documentation of Dkron\u0026rsquo;s command-line interface for http://dkron.io/. It creates one Markdown file per command with front matter suitable for rendering in Hugo.\ndkron doc [flags] Options  --dir string the directory to write the doc. (default \u0026quot;/tmp/dkrondoc/\u0026quot;) -h, --help help for doc Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/v1.2/cli/dkron_keygen/",
	"title": "dkron keygen",
	"tags": [],
	"description": "",
	"content": "dkron keygen Generates a new encryption key\nSynopsis Generates a new encryption key that can be used to configure the agent to encrypt traffic. The output of this command is already in the proper format that the agent expects.\ndkron keygen [flags] Options  -h, --help help for keygen Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/v1.2/cli/dkron_version/",
	"title": "dkron version",
	"tags": [],
	"description": "",
	"content": "dkron version Show version\nSynopsis Show the version\ndkron version [flags] Options  -h, --help help for version Options inherited from parent commands  --config string config file (default is /etc/dkron/dkron.yml) SEE ALSO  dkron\t- Professional distributed job scheduling system  Auto generated by spf13/cobra on 21-Jan-2019 "
},
{
	"uri": "/",
	"title": "Dkron - Distributed job scheduling system",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/_header/",
	"title": "header",
	"tags": [],
	"description": "",
	"content": "  "
},
{
	"uri": "/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Distributed Works © 2015 - 2020 Victor Castell - victor@distrib.works\n"
},
{
	"uri": "/v1.2/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Distributed Works © 2015 - 2019 Victor Castell - victor@distrib.works\n"
},
{
	"uri": "/v2.0/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Distributed Works © 2015 - 2020 Victor Castell - victor@distrib.works\n"
},
{
	"uri": "/pro/acls/",
	"title": "Access Control",
	"tags": [],
	"description": "",
	"content": "Access Control (Preview) This feature is in preview and is subject to big changes\n Dkron provides an optional Access Control List (ACL) system which can be used to control access to data and APIs. The ACL is Capability-based, relying on policies to determine which fine grained rules can be applied. Dkron\u0026rsquo;s capability based ACL system is very similar to common ACL systems you are used to.\nACL System Overview Dkron\u0026rsquo;s ACL system is implemented with the CNCF Open Policy Agent bringing a powerful system to suit your needs.\nThe ACL system is designed to be easy to use and fast to enforce while providing administrative insight. At the highest level, there are two major components to the ACL system:\n  OPA policy engine. OPA provices policy decission making decoupling Dkron integrates OPA as a library and provides a default policy rules written in the OPA Policy language that implements a set of enforcing rules on request params to the API that are ready to use for most use cases. You don not need to learn the OPA Policy language to start using Dkron\u0026rsquo;s ACL system, but you can modify the default policy rules to adapt to your use case if you need to. Read more in OPA Docs\n  ACL Policies. Dkron\u0026rsquo;s ACL policies are simple JSON documents that define patterns to allow access to resources. You can find below an example ACL policy that works with the default OPA policy. The ACL JSON structure is not rigid you can adapt it to add new features in combination with the OPA Policy rules.\n  This guide is based on the usage of the default OPA Rego Policy\n Configuring ACLs ACLs are not enabled by default and must be enabled. To enable ACLs simply create an ACL policy using the API. Below you can find the most basic example of an ACL policy:\nBasic example policy:\ncurl localhost:8080/v1/acl/policies -d '{ \u0026quot;path\u0026quot;: { \u0026quot;/v1\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;read\u0026quot;, ] }, \u0026quot;/v1/**\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;create\u0026quot;, \u0026quot;read\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;delete\u0026quot;, \u0026quot;list\u0026quot; ] } } }' This policy allows any request to the API. As you can see paths uses glob patterns, and capabilities allow operations on resources.\nACLs also allows templating, providing the ability to allow or deny operations to certain resource by patterns without having to hardcode values in policies.\nFor example, we can for limit job actions on certain resources based on the provided token via the accepted header X-Dkron-Token on the request:\nExample policy:\ncurl localhost:8080/v1/acl/policies -d '{ \u0026quot;path\u0026quot;: { \u0026quot;/v1/members\u0026quot;: { \u0026quot;capabilities\u0026quot;: [\u0026quot;read\u0026quot;] }, \u0026quot;/v1/jobs\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;list\u0026quot;, \u0026quot;read\u0026quot; ] }, \u0026quot;/v1/jobs/{{.Token}}-*\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;create\u0026quot;, \u0026quot;read\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;delete\u0026quot; ] } } }' This policy will allow all operations on jobs starting with [Token]-job_name, but will deny manipulation of jobs that doesn\u0026rsquo;t match the pattern.\nDisable ACLs As an administrator you will need to edit policies. Currently to be able to edit ACLs if you get locked out, you need to edit the default Rego file and disable enforcement completely. Edit the file located in policies/main.rego and change the default allow directive to true:\ndefault allow = false -\u0026gt; true This way the policy engine always evaluates to true, allowing any operation again. To restore ACL enforcemen, edit again the default allow line and set it back to false.\n"
},
{
	"uri": "/v2.0/pro/acls/",
	"title": "Access Control",
	"tags": [],
	"description": "",
	"content": "Access Control (Preview) This feature is in preview and is subject to big changes\n Dkron provides an optional Access Control List (ACL) system which can be used to control access to data and APIs. The ACL is Capability-based, relying on policies to determine which fine grained rules can be applied. Dkron\u0026rsquo;s capability based ACL system is very similar to common ACL systems you are used to.\nACL System Overview Dkron\u0026rsquo;s ACL system is implemented with the CNCF Open Policy Agent bringing a powerful system to suit your needs.\nThe ACL system is designed to be easy to use and fast to enforce while providing administrative insight. At the highest level, there are two major components to the ACL system:\n  OPA policy engine. OPA provices policy decission making decoupling Dkron integrates OPA as a library and provides a default policy rules written in the OPA Policy language that implements a set of enforcing rules on request params to the API that are ready to use for most use cases. You don not need to learn the OPA Policy language to start using Dkron\u0026rsquo;s ACL system, but you can modify the default policy rules to adapt to your use case if you need to. Read more in OPA Docs\n  ACL Policies. Dkron\u0026rsquo;s ACL policies are simple JSON documents that define patterns to allow access to resources. You can find below an example ACL policy that works with the default OPA policy. The ACL JSON structure is not rigid you can adapt it to add new features in combination with the OPA Policy rules.\n  This guide is based on the usage of the default OPA Rego Policy\n Configuring ACLs ACLs are not enabled by default and must be enabled. To enable ACLs simply create an ACL policy using the API. Below you can find the most basic example of an ACL policy:\nBasic example policy:\ncurl localhost:8080/v1/acl/policies -d '{ \u0026quot;path\u0026quot;: { \u0026quot;/v1\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;read\u0026quot;, ] }, \u0026quot;/v1/**\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;create\u0026quot;, \u0026quot;read\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;delete\u0026quot;, \u0026quot;list\u0026quot; ] } } }' This policy allows any request to the API. As you can see paths uses glob patterns, and capabilities allow operations on resources.\nACLs also allows templating, providing the ability to allow or deny operations to certain resource by patterns without having to hardcode values in policies.\nFor example, we can for limit job actions on certain resources based on the provided token via the accepted header X-Dkron-Token on the request:\nExample policy:\ncurl localhost:8080/v1/acl/policies -d '{ \u0026quot;path\u0026quot;: { \u0026quot;/v1/members\u0026quot;: { \u0026quot;capabilities\u0026quot;: [\u0026quot;read\u0026quot;] }, \u0026quot;/v1/jobs\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;list\u0026quot;, \u0026quot;read\u0026quot; ] }, \u0026quot;/v1/jobs/{{.Token}}-*\u0026quot;: { \u0026quot;capabilities\u0026quot;: [ \u0026quot;create\u0026quot;, \u0026quot;read\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;delete\u0026quot; ] } } }' This policy will allow all operations on jobs starting with [Token]-job_name, but will deny manipulation of jobs that doesn\u0026rsquo;t match the pattern.\nDisable ACLs As an administrator you will need to edit policies. Currently to be able to edit ACLs if you get locked out, you need to edit the default Rego file and disable enforcement completely. Edit the file located in policies/main.rego and change the default allow directive to true:\ndefault allow = false -\u0026gt; true This way the policy engine always evaluates to true, allowing any operation again. To restore ACL enforcemen, edit again the default allow line and set it back to false.\n"
},
{
	"uri": "/pro/auth/",
	"title": "Authentication",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has the ability to be configured to use HTTP basic auth.\nAuthentication can be set using these parameters in the dkron config file:\n# dkron.yml username: dkron_admin password: adminpassword This will enable auth on the WebUI and for the API.\n"
},
{
	"uri": "/v2.0/pro/auth/",
	"title": "Authentication",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has the ability to be configured to use HTTP basic auth.\nAuthentication can be set using these parameters in the dkron config file:\n# dkron.yml username: dkron_admin password: adminpassword This will enable auth on the WebUI and for the API.\n"
},
{
	"uri": "/v1.2/pro/auth/",
	"title": "Authorization",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has the ability to be configured to use HTTP basic auth.\nAuthentication can be set using these parameters in the dkron config file:\n# dkron.yml username: dkron_admin password: adminpassword This will enable auth on the WebUI and for the API.\n"
},
{
	"uri": "/pro/executors/ecs/",
	"title": "AWS ECS Executor",
	"tags": [],
	"description": "",
	"content": "The ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output.\nTo configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS.\nTo allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1460720941000\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecs:RunTask\u0026#34;, \u0026#34;ecs:DescribeTasks\u0026#34;, \u0026#34;ecs:DescribeTaskDefinition\u0026#34;, \u0026#34;logs:FilterLogEvents\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } To configure a job to be run with the ECS executor:\nExample using an existing taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefName\u0026#34;: \u0026#34;mytaskdef-family\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;mycontainer\u0026#34;, \u0026#34;overrides\u0026#34;: \u0026#34;echo,\\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34; } } Example using a provided taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefBody\u0026#34;: \u0026#34;{\\\u0026#34;containerDefinitions\\\u0026#34;: [{\\\u0026#34;essential\\\u0026#34;: true,\\\u0026#34;image\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;,\\\u0026#34;memory\\\u0026#34;: 100,\\\u0026#34;name\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;}],\\\u0026#34;family\\\u0026#34;: \\\u0026#34;helloworld\\\u0026#34;}\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;fargate\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;maxAttempts\u0026#34;: \u0026#34;5000\u0026#34; } } This is the complete list of configuration parameters of the plugin:\ntaskdefBody taskdefName region cluster logGroup fargate securityGroup subnet env service overrides maxAttempts // Defaults to 2000, will perform a check every 6s * 2000 times waiting a total of 12000s or 3.3h "
},
{
	"uri": "/v1.2/pro/executors/ecs/",
	"title": "AWS ECS Executor",
	"tags": [],
	"description": "",
	"content": "The ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output.\nTo configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS.\nTo allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1460720941000\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecs:RunTask\u0026#34;, \u0026#34;ecs:DescribeTasks\u0026#34;, \u0026#34;ecs:DescribeTaskDefinition\u0026#34;, \u0026#34;logs:FilterLogEvents\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } To configure a job to be run with the ECS executor:\nExample using an existing taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefName\u0026#34;: \u0026#34;mytaskdef-family\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;mycontainer\u0026#34;, \u0026#34;overrides\u0026#34;: \u0026#34;echo,\\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34; } } Example using a provided taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefBody\u0026#34;: \u0026#34;{\\\u0026#34;containerDefinitions\\\u0026#34;: [{\\\u0026#34;essential\\\u0026#34;: true,\\\u0026#34;image\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;,\\\u0026#34;memory\\\u0026#34;: 100,\\\u0026#34;name\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;}],\\\u0026#34;family\\\u0026#34;: \\\u0026#34;helloworld\\\u0026#34;}\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;fargate\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;maxAttempts\u0026#34;: \u0026#34;5000\u0026#34; } } This is the complete list of configuration parameters of the plugin:\ntaskdefBody taskdefName region cluster logGroup fargate securityGroup subnet env service overrides maxAttempts // Defaults to 2000, will perform a check every 6s * 2000 times waiting a total of 12000s or 3.3h "
},
{
	"uri": "/v2.0/pro/executors/ecs/",
	"title": "AWS ECS Executor",
	"tags": [],
	"description": "",
	"content": "The ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output.\nTo configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS.\nTo allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1460720941000\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecs:RunTask\u0026#34;, \u0026#34;ecs:DescribeTasks\u0026#34;, \u0026#34;ecs:DescribeTaskDefinition\u0026#34;, \u0026#34;logs:FilterLogEvents\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } To configure a job to be run with the ECS executor:\nExample using an existing taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefName\u0026#34;: \u0026#34;mytaskdef-family\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;mycontainer\u0026#34;, \u0026#34;overrides\u0026#34;: \u0026#34;echo,\\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34; } } Example using a provided taskdef\n{ \u0026#34;executor\u0026#34;: \u0026#34;ecs\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;taskdefBody\u0026#34;: \u0026#34;{\\\u0026#34;containerDefinitions\\\u0026#34;: [{\\\u0026#34;essential\\\u0026#34;: true,\\\u0026#34;image\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;,\\\u0026#34;memory\\\u0026#34;: 100,\\\u0026#34;name\\\u0026#34;: \\\u0026#34;hello-world\\\u0026#34;}],\\\u0026#34;family\\\u0026#34;: \\\u0026#34;helloworld\\\u0026#34;}\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;eu-west-1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;fargate\u0026#34;: \u0026#34;yes\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34;, \u0026#34;maxAttempts\u0026#34;: \u0026#34;5000\u0026#34; } } This is the complete list of configuration parameters of the plugin:\ntaskdefBody taskdefName region cluster logGroup fargate securityGroup subnet env service overrides maxAttempts // Defaults to 2000, will perform a check every 6s * 2000 times waiting a total of 12000s or 3.3h "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/usage/cloud-auto-join/",
	"title": "Cloud Auto-join",
	"tags": [],
	"description": "Dkron supports automatic cluster joining using cloud metadata on various providers.",
	"content": "Cloud Auto-joining As of Dkron 2.0.0, retry-join accepts a unified interface using the go-discover library for doing automatic cluster joining using cloud metadata. To use retry-join with a supported cloud provider, specify the configuration on the command line or configuration file as a key=value key=value ... string.\nIf the values contain spaces, equals, backslashes or double quotes then they need to be double quoted and the usual escaping rules apply.\n$ dkron agent --retry-join \u0026#39;provider=my-cloud config=val config2=\u0026#34;some other val\u0026#34; ...\u0026#39; or via a configuration file:\nretry-join\u0026#34;: [\u0026#34;provider=my-cloud config=val config2=\\\u0026#34;some other val\\\u0026#34; ...\u0026#34;] The cloud provider-specific configurations are detailed below. This can be combined with static IP or DNS addresses or even multiple configurations for different providers.\nIn order to use discovery behind a proxy, you will need to set HTTP_PROXY, HTTPS_PROXY and NO_PROXY environment variables per Golang net/http library.\nThe following sections give the options specific to each supported cloud provider.\nAmazon EC2 This returns the first private IP address of all servers in the given region which have the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=aws tag_key=... tag_value=...\u0026#34; retry-join: [\u0026#34;provider=aws tag_key=... tag_value=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;aws\u0026rdquo; in this case). tag_key (required) - the key of the tag to auto-join on. tag_value (required) - the value of the tag to auto-join on. region (optional) - the AWS region to authenticate in. addr_type (optional) - the type of address to discover: private_v4, public_v4, public_v6. Default is private_v4. (\u0026gt;= 1.0) access_key_id (optional) - the AWS access key for authentication (see below for more information about authenticating). secret_access_key (optional) - the AWS secret access key for authentication (see below for more information about authenticating).  Authentication \u0026amp; Precedence  Static credentials access_key_id=... secret_access_key=... Environment variables (AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY) Shared credentials file (~/.aws/credentials or the path specified by AWS_SHARED_CREDENTIALS_FILE) ECS task role metadata (container-specific). EC2 instance role metadata.  The only required IAM permission is ec2:DescribeInstances, and it is recommended that you make a dedicated key used only for auto-joining. If the region is omitted it will be discovered through the local instance\u0026rsquo;s EC2 metadata endpoint.\nMicrosoft Azure This returns the first private IP address of all servers in the given region which have the given tag_key and tag_value in the tenant and subscription, or in the given resource_group of a vm_scale_set for Virtual Machine Scale Sets.\n$ dkron agent --retry-join \u0026#34;provider=azure tag_name=... tag_value=... tenant_id=... client_id=... subscription_id=... secret_access_key=...\u0026#34; retry-join: [\u0026#34;provider=azure tag_name=... tag_value=... tenant_id=... client_id=... subscription_id=... secret_access_key=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;azure\u0026rdquo; in this case). tenant_id (required) - the tenant to join machines in. client_id (required) - the client to authenticate with. secret_access_key (required) - the secret client key. NOTE This value often may have an equals sign in it\u0026rsquo;s value, especially if generated from the Azure Portal, so is important to wrap in single quotes eg. secret_acccess_key='fpOfcHQJAQBczjAxiVpeyLmX1M0M0KPBST+GU2GvEN4='  Variables can also be provided by environmental variables:\n ARM_SUBSCRIPTION_ID for subscription ARM_TENANT_ID for tenant ARM_CLIENT_ID for client ARM_CLIENT_SECRET for secret access key  Use these configuration parameters when using tags:\n tag_name - the name of the tag to auto-join on. tag_value - the value of the tag to auto-join on.  Use these configuration parameters (instead of tag_name and tag_value) when using Virtual Machine Scale Sets (Dkron 1.0.3 and later):\n resource_group - the name of the resource group to filter on. vm_scale_set - the name of the virtual machine scale set to filter on.  When using tags the only permission needed is Microsoft.Network/networkInterfaces.\nWhen using Virtual Machine Scale Sets the only role action needed is Microsoft.Compute/virtualMachineScaleSets/*/read.\nGoogle Compute Engine This returns the first private IP address of all servers in the given project which have the given tag_value.\n$ dkron agent --retry-join \u0026#34;provider=gce project_name=... tag_value=...\u0026#34; retry_join: [\u0026#34;provider=gce project_name=... tag_value=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;gce\u0026rdquo; in this case). tag_value (required) - the value of the tag to auto-join on. project_name (optional) - the name of the project to auto-join on. Discovered if not set. zone_pattern (optional) - the list of zones can be restricted through an RE2 compatible regular expression. If omitted, servers in all zones are returned. credentials_file (optional) - the credentials file for authentication. Note, if you set -config-dir do not store the credentials.json file in the configuration directory as it will be parsed as a config file and Dkron will fail to start. See below for more information.  Authentication \u0026amp; Precedence  Use credentials from credentials_file, if provided. Use JSON file from GOOGLE_APPLICATION_CREDENTIALS environment variable. Use JSON file in a location known to the gcloud command-line tool.  On Windows, this is %APPDATA%/gcloud/application_default_credentials.json. On other systems, $HOME/.config/gcloud/application_default_credentials.json.   On Google Compute Engine, use credentials from the metadata server. In this final case any provided scopes are ignored.  Discovery requires a GCE Service Account. Credentials are searched using the following paths, in order of precedence.\nIBM SoftLayer This returns the first private IP address of all servers for the given datacenter with the given tag_value.\n$ dkron agent --retry-join \u0026#34;provider=softlayer datacenter=... tag_value=... username=... api_key=...\u0026#34; retry-join: [\u0026#34;provider=softlayer datacenter=... tag_value=... username=... api_key=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;softlayer\u0026rdquo; in this case). datacenter (required) - the name of the datacenter to auto-join in. tag_value (required) - the value of the tag to auto-join on. username (required) - the username to use for auth. api_key (required) - the api key to use for auth.  Aliyun (Alibaba Cloud) This returns the first private IP address of all servers for the given region with the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=aliyun region=... tag_key=dkron tag_value=... access_key_id=... access_key_secret=...\u0026#34; retry-join: [\u0026#34;provider=aliyun region=... tag_key=dkron tag_value=... access_key_id=... access_key_secret=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;aliyun\u0026rdquo; in this case). region (required) - the name of the region. tag_key (required) - the key of the tag to auto-join on. tag_value (required) - the value of the tag to auto-join on. access_key_id (required) -the access key to use for auth. access_key_secret (required) - the secret key to use for auth.  The required RAM permission is ecs:DescribeInstances. It is recommended you make a dedicated key used only for auto-joining.\nDigital Ocean This returns the first private IP address of all servers for the given region with the given tag_name.\n$ dkron agent --retry-join \u0026#34;provider=digitalocean region=... tag_name=... api_token=...\u0026#34; retry-join: [\u0026#34;provider=digitalocean region=... tag_name=... api_token=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;digitalocean\u0026rdquo; in this case). region (required) - the name of the region. tag_name (required) - the value of the tag to auto-join on. api_token (required) -the token to use for auth.  Openstack This returns the first private IP address of all servers for the given region with the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=os tag_key=dkron tag_value=server username=... password=... auth_url=...\u0026#34; retry-join: [\u0026#34;provider=os tag_key=dkron tag_value=server username=... password=... auth_url=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;os\u0026rdquo; in this case). tag_key (required) - the key of the tag to auto-join on. tag_value (required) - the value of the tag to auto-join on. project_id (optional) - the id of the project (tenant id). username (optional) - the username to use for auth. password (optional) - the password to use for auth. token (optional) - the token to use for auth. auth_url (optional) - the identity endpoint to use for auth. insecure (optional) - indicates whether the API certificate should not be checked. Any value means true.  The configuration can also be provided by environment variables.\nScaleway This returns the first private IP address of all servers for the given region with the given tag_name.\n$ dkron agent --retry-join \u0026#34;provider=scaleway organization=my-org tag_name=dkron-server token=... region=...\u0026#34; retry-join: [\u0026#34;provider=scaleway organization=my-org tag_name=dkron-server token=... region=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;scaleway\u0026rdquo; in this case). region (required) - the name of the region. tag_name (required) - the name of the tag to auto-join on. organization (required) - the organization access key to use for auth (equal to access key). token (required) - the token to use for auth.  Joyent Triton This returns the first PrimaryIP addresses for all servers with the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=triton account=testaccount url=https://us-sw-1.api.joyentcloud.com key_id=... tag_key=dkron-role tag_value=server\u0026#34; retry-join: [\u0026#34;provider=triton account=testaccount url=https://us-sw-1.api.joyentcloud.com key_id=... tag_key=dkron-role tag_value=server\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;triton\u0026rdquo; in this case). account (required) - the name of the account. url (required) - the URL of the Triton api endpoint to use. key_id (required) - the key id to use. tag_key (optional) - the instance tag key to use. tag_value (optional) - the tag value to use.  vSphere This returns the first private IP address of all servers for the given region with the given tag_name and category_name.\n$ dkron agent --retry-join \u0026#34;provider=vsphere category_name=dkron-role tag_name=dkron-server host=... user=... password=... insecure_ssl=[true|false]\u0026#34; retry-join: [\u0026#34;provider=vsphere category_name=dkron-role tag_name=dkron-server host=... user=... password=... insecure_ssl=[true|false]\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;vsphere\u0026rdquo; is the provider here) tag_name (required) - The name of the tag to look up. category_name (required) - The category of the tag to look up. host (required) - The host of the vSphere server to connect to. user (required) - The username to connect as. password (required) - The password of the user to connect to vSphere as. insecure_ssl (optional) - Whether or not to skip SSL certificate validation. timeout (optional) - Discovery context timeout (default: 10m)  Packet This returns the first private IP address (or the IP address of address type) of all servers with the given project and auth_token.\n$ dkron agent --retry-join \u0026#34;provider=packet auth_token=token project=uuid url=... address_type=...\u0026#34; retry-join: [\u0026#34;provider=packet auth_token=token project=uuid url=... address_type=...\u0026#34;]  provider (required)\t-\tthe name of the provider (\u0026ldquo;packet\u0026rdquo; is the provider here) project (required) - the UUID of packet project auth_token (required) - the authentication token for packet url (optional) - a REST URL for packet address_type (optional) - the type of address to check for in this provider (\u0026ldquo;private_v4\u0026rdquo;, \u0026ldquo;public_v4\u0026rdquo; or \u0026ldquo;public_v6\u0026rdquo;. Defaults to \u0026ldquo;private_v4\u0026rdquo;)  Kubernetes (k8s) The Kubernetes provider finds the IP addresses of pods with the matching label or field selector. This is useful for non-Kubernetes agents that are joining a server cluster running within Kubernetes.\nThe pod IP is used by default, which requires that the agent connecting can network to the pod IP. The host_network boolean can be set to true to use the host IP instead, but this requires the agent ports (Gossip, RPC, etc.) to be exported to the host as well.\nBy default, no port is specified. This causes Dkron to use the default gossip port (default behavior with all join requests). The pod may specify the dkron.hashicorp.com/auto-join-port annotation to set the port. The value may be an integer or a named port.\n$ dkron agent --retry-join \u0026#34;provider=k8s label_selector=\\\u0026#34;app=dkron,component=server\\\u0026#34;\u0026#34; retry-join: [\u0026#34;provider=k8s label_selector=...\u0026#34;]  provider (required)\t-\tthe name of the provider (\u0026ldquo;k8s\u0026rdquo; is the provider here) kubeconfig (optional) - path to the kubeconfig file. If this isn\u0026rsquo;t set, then in-cluster auth will be attempted. If that fails, the default kubeconfig paths are tried ($HOME/.kube/config). namespace (optional) - the namespace to search for pods. If this isn\u0026rsquo;t set, it defaults to all namespaces. label_selector (optional) - the label selector for matching pods. field_selector (optional) - the field selector for matching pods.  "
},
{
	"uri": "/v2.0/usage/cloud-auto-join/",
	"title": "Cloud Auto-join",
	"tags": [],
	"description": "Dkron supports automatic cluster joining using cloud metadata on various providers.",
	"content": "Cloud Auto-joining As of Dkron 2.0.0, retry-join accepts a unified interface using the go-discover library for doing automatic cluster joining using cloud metadata. To use retry-join with a supported cloud provider, specify the configuration on the command line or configuration file as a key=value key=value ... string.\nIf the values contain spaces, equals, backslashes or double quotes then they need to be double quoted and the usual escaping rules apply.\n$ dkron agent --retry-join \u0026#39;provider=my-cloud config=val config2=\u0026#34;some other val\u0026#34; ...\u0026#39; or via a configuration file:\nretry-join\u0026#34;: [\u0026#34;provider=my-cloud config=val config2=\\\u0026#34;some other val\\\u0026#34; ...\u0026#34;] The cloud provider-specific configurations are detailed below. This can be combined with static IP or DNS addresses or even multiple configurations for different providers.\nIn order to use discovery behind a proxy, you will need to set HTTP_PROXY, HTTPS_PROXY and NO_PROXY environment variables per Golang net/http library.\nThe following sections give the options specific to each supported cloud provider.\nAmazon EC2 This returns the first private IP address of all servers in the given region which have the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=aws tag_key=... tag_value=...\u0026#34; retry-join: [\u0026#34;provider=aws tag_key=... tag_value=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;aws\u0026rdquo; in this case). tag_key (required) - the key of the tag to auto-join on. tag_value (required) - the value of the tag to auto-join on. region (optional) - the AWS region to authenticate in. addr_type (optional) - the type of address to discover: private_v4, public_v4, public_v6. Default is private_v4. (\u0026gt;= 1.0) access_key_id (optional) - the AWS access key for authentication (see below for more information about authenticating). secret_access_key (optional) - the AWS secret access key for authentication (see below for more information about authenticating).  Authentication \u0026amp; Precedence  Static credentials access_key_id=... secret_access_key=... Environment variables (AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY) Shared credentials file (~/.aws/credentials or the path specified by AWS_SHARED_CREDENTIALS_FILE) ECS task role metadata (container-specific). EC2 instance role metadata.  The only required IAM permission is ec2:DescribeInstances, and it is recommended that you make a dedicated key used only for auto-joining. If the region is omitted it will be discovered through the local instance\u0026rsquo;s EC2 metadata endpoint.\nMicrosoft Azure This returns the first private IP address of all servers in the given region which have the given tag_key and tag_value in the tenant and subscription, or in the given resource_group of a vm_scale_set for Virtual Machine Scale Sets.\n$ dkron agent --retry-join \u0026#34;provider=azure tag_name=... tag_value=... tenant_id=... client_id=... subscription_id=... secret_access_key=...\u0026#34; retry-join: [\u0026#34;provider=azure tag_name=... tag_value=... tenant_id=... client_id=... subscription_id=... secret_access_key=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;azure\u0026rdquo; in this case). tenant_id (required) - the tenant to join machines in. client_id (required) - the client to authenticate with. secret_access_key (required) - the secret client key. NOTE This value often may have an equals sign in it\u0026rsquo;s value, especially if generated from the Azure Portal, so is important to wrap in single quotes eg. secret_acccess_key='fpOfcHQJAQBczjAxiVpeyLmX1M0M0KPBST+GU2GvEN4='  Variables can also be provided by environmental variables:\n ARM_SUBSCRIPTION_ID for subscription ARM_TENANT_ID for tenant ARM_CLIENT_ID for client ARM_CLIENT_SECRET for secret access key  Use these configuration parameters when using tags:\n tag_name - the name of the tag to auto-join on. tag_value - the value of the tag to auto-join on.  Use these configuration parameters (instead of tag_name and tag_value) when using Virtual Machine Scale Sets (Dkron 1.0.3 and later):\n resource_group - the name of the resource group to filter on. vm_scale_set - the name of the virtual machine scale set to filter on.  When using tags the only permission needed is Microsoft.Network/networkInterfaces.\nWhen using Virtual Machine Scale Sets the only role action needed is Microsoft.Compute/virtualMachineScaleSets/*/read.\nGoogle Compute Engine This returns the first private IP address of all servers in the given project which have the given tag_value.\n$ dkron agent --retry-join \u0026#34;provider=gce project_name=... tag_value=...\u0026#34; retry_join: [\u0026#34;provider=gce project_name=... tag_value=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;gce\u0026rdquo; in this case). tag_value (required) - the value of the tag to auto-join on. project_name (optional) - the name of the project to auto-join on. Discovered if not set. zone_pattern (optional) - the list of zones can be restricted through an RE2 compatible regular expression. If omitted, servers in all zones are returned. credentials_file (optional) - the credentials file for authentication. Note, if you set -config-dir do not store the credentials.json file in the configuration directory as it will be parsed as a config file and Dkron will fail to start. See below for more information.  Authentication \u0026amp; Precedence  Use credentials from credentials_file, if provided. Use JSON file from GOOGLE_APPLICATION_CREDENTIALS environment variable. Use JSON file in a location known to the gcloud command-line tool.  On Windows, this is %APPDATA%/gcloud/application_default_credentials.json. On other systems, $HOME/.config/gcloud/application_default_credentials.json.   On Google Compute Engine, use credentials from the metadata server. In this final case any provided scopes are ignored.  Discovery requires a GCE Service Account. Credentials are searched using the following paths, in order of precedence.\nIBM SoftLayer This returns the first private IP address of all servers for the given datacenter with the given tag_value.\n$ dkron agent --retry-join \u0026#34;provider=softlayer datacenter=... tag_value=... username=... api_key=...\u0026#34; retry-join: [\u0026#34;provider=softlayer datacenter=... tag_value=... username=... api_key=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;softlayer\u0026rdquo; in this case). datacenter (required) - the name of the datacenter to auto-join in. tag_value (required) - the value of the tag to auto-join on. username (required) - the username to use for auth. api_key (required) - the api key to use for auth.  Aliyun (Alibaba Cloud) This returns the first private IP address of all servers for the given region with the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=aliyun region=... tag_key=dkron tag_value=... access_key_id=... access_key_secret=...\u0026#34; retry-join: [\u0026#34;provider=aliyun region=... tag_key=dkron tag_value=... access_key_id=... access_key_secret=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;aliyun\u0026rdquo; in this case). region (required) - the name of the region. tag_key (required) - the key of the tag to auto-join on. tag_value (required) - the value of the tag to auto-join on. access_key_id (required) -the access key to use for auth. access_key_secret (required) - the secret key to use for auth.  The required RAM permission is ecs:DescribeInstances. It is recommended you make a dedicated key used only for auto-joining.\nDigital Ocean This returns the first private IP address of all servers for the given region with the given tag_name.\n$ dkron agent --retry-join \u0026#34;provider=digitalocean region=... tag_name=... api_token=...\u0026#34; retry-join: [\u0026#34;provider=digitalocean region=... tag_name=... api_token=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;digitalocean\u0026rdquo; in this case). region (required) - the name of the region. tag_name (required) - the value of the tag to auto-join on. api_token (required) -the token to use for auth.  Openstack This returns the first private IP address of all servers for the given region with the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=os tag_key=dkron tag_value=server username=... password=... auth_url=...\u0026#34; retry-join: [\u0026#34;provider=os tag_key=dkron tag_value=server username=... password=... auth_url=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;os\u0026rdquo; in this case). tag_key (required) - the key of the tag to auto-join on. tag_value (required) - the value of the tag to auto-join on. project_id (optional) - the id of the project (tenant id). username (optional) - the username to use for auth. password (optional) - the password to use for auth. token (optional) - the token to use for auth. auth_url (optional) - the identity endpoint to use for auth. insecure (optional) - indicates whether the API certificate should not be checked. Any value means true.  The configuration can also be provided by environment variables.\nScaleway This returns the first private IP address of all servers for the given region with the given tag_name.\n$ dkron agent --retry-join \u0026#34;provider=scaleway organization=my-org tag_name=dkron-server token=... region=...\u0026#34; retry-join: [\u0026#34;provider=scaleway organization=my-org tag_name=dkron-server token=... region=...\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;scaleway\u0026rdquo; in this case). region (required) - the name of the region. tag_name (required) - the name of the tag to auto-join on. organization (required) - the organization access key to use for auth (equal to access key). token (required) - the token to use for auth.  Joyent Triton This returns the first PrimaryIP addresses for all servers with the given tag_key and tag_value.\n$ dkron agent --retry-join \u0026#34;provider=triton account=testaccount url=https://us-sw-1.api.joyentcloud.com key_id=... tag_key=dkron-role tag_value=server\u0026#34; retry-join: [\u0026#34;provider=triton account=testaccount url=https://us-sw-1.api.joyentcloud.com key_id=... tag_key=dkron-role tag_value=server\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;triton\u0026rdquo; in this case). account (required) - the name of the account. url (required) - the URL of the Triton api endpoint to use. key_id (required) - the key id to use. tag_key (optional) - the instance tag key to use. tag_value (optional) - the tag value to use.  vSphere This returns the first private IP address of all servers for the given region with the given tag_name and category_name.\n$ dkron agent --retry-join \u0026#34;provider=vsphere category_name=dkron-role tag_name=dkron-server host=... user=... password=... insecure_ssl=[true|false]\u0026#34; retry-join: [\u0026#34;provider=vsphere category_name=dkron-role tag_name=dkron-server host=... user=... password=... insecure_ssl=[true|false]\u0026#34;]  provider (required) - the name of the provider (\u0026ldquo;vsphere\u0026rdquo; is the provider here) tag_name (required) - The name of the tag to look up. category_name (required) - The category of the tag to look up. host (required) - The host of the vSphere server to connect to. user (required) - The username to connect as. password (required) - The password of the user to connect to vSphere as. insecure_ssl (optional) - Whether or not to skip SSL certificate validation. timeout (optional) - Discovery context timeout (default: 10m)  Packet This returns the first private IP address (or the IP address of address type) of all servers with the given project and auth_token.\n$ dkron agent --retry-join \u0026#34;provider=packet auth_token=token project=uuid url=... address_type=...\u0026#34; retry-join: [\u0026#34;provider=packet auth_token=token project=uuid url=... address_type=...\u0026#34;]  provider (required)\t-\tthe name of the provider (\u0026ldquo;packet\u0026rdquo; is the provider here) project (required) - the UUID of packet project auth_token (required) - the authentication token for packet url (optional) - a REST URL for packet address_type (optional) - the type of address to check for in this provider (\u0026ldquo;private_v4\u0026rdquo;, \u0026ldquo;public_v4\u0026rdquo; or \u0026ldquo;public_v6\u0026rdquo;. Defaults to \u0026ldquo;private_v4\u0026rdquo;)  Kubernetes (k8s) The Kubernetes provider finds the IP addresses of pods with the matching label or field selector. This is useful for non-Kubernetes agents that are joining a server cluster running within Kubernetes.\nThe pod IP is used by default, which requires that the agent connecting can network to the pod IP. The host_network boolean can be set to true to use the host IP instead, but this requires the agent ports (Gossip, RPC, etc.) to be exported to the host as well.\nBy default, no port is specified. This causes Dkron to use the default gossip port (default behavior with all join requests). The pod may specify the dkron.hashicorp.com/auto-join-port annotation to set the port. The value may be an integer or a named port.\n$ dkron agent --retry-join \u0026#34;provider=k8s label_selector=\\\u0026#34;app=dkron,component=server\\\u0026#34;\u0026#34; retry-join: [\u0026#34;provider=k8s label_selector=...\u0026#34;]  provider (required)\t-\tthe name of the provider (\u0026ldquo;k8s\u0026rdquo; is the provider here) kubeconfig (optional) - path to the kubeconfig file. If this isn\u0026rsquo;t set, then in-cluster auth will be attempted. If that fails, the default kubeconfig paths are tried ($HOME/.kube/config). namespace (optional) - the namespace to search for pods. If this isn\u0026rsquo;t set, it defaults to all namespaces. label_selector (optional) - the label selector for matching pods. field_selector (optional) - the field selector for matching pods.  "
},
{
	"uri": "/usage/clustering/",
	"title": "Clustering",
	"tags": [],
	"description": "",
	"content": "Configure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run.\nManually bootstrapping a Dkron cluster does not rely on additional tooling, but does require operator participation in the cluster formation process. When bootstrapping, Dkron servers and clients must be started and informed with the address of at least one Dkron server.\nAs you can tell, this creates a chicken-and-egg problem where one server must first be fully bootstrapped and configured before the remaining servers and clients can join the cluster. This requirement can add additional provisioning time as well as ordered dependencies during provisioning.\nFirst, we bootstrap a single Dkron server and capture its IP address. After we have that nodes IP address, we place this address in the configuration.\n First bootstrap a node with a configuration like this:  # dkron.yml server: true bootstrap-expect: 1  Then stop the bootstrapped server and capture the server IP address.\n  To form a cluster, configure server nodes (including the bootstrapped server) with the address of its peers as in the following example:\n  # dkron.yml server: true bootstrap-expect: 3 join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 "
},
{
	"uri": "/v1.2/pro/clustering/",
	"title": "Clustering",
	"tags": [],
	"description": "",
	"content": "Configure a cluster First follow the Dkron clustering guide then you can continue with this guide.\nThe embedded store also needs to know its peers, it needs its own configuration as in the following example:\n# etcd.conf.yaml # Initial cluster configuration for bootstrapping. initial-cluster: dkron1=https://10.19.3.9:2380,dkron2=https://10.19.4.64:2380,dkron3=https://10.19.7.215:2380 With this configuration Dkron Pro should start in cluster mode with embedded storage.\nFor a more in detail guide of clustering with etcd follow this guide: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md\n"
},
{
	"uri": "/v1.2/usage/clustering/",
	"title": "Clustering",
	"tags": [],
	"description": "",
	"content": "Configure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run.\nTo form a cluster, server nodes need to know the address of its peers as in the following example:\n# dkron.yml join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 Etcd For a more in detail guide of clustering with etcd follow this guide: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md\n"
},
{
	"uri": "/v2.0/usage/clustering/",
	"title": "Clustering",
	"tags": [],
	"description": "",
	"content": "Configure a cluster Dkron can run in HA mode, avoiding SPOFs, this mode provides better scalability and better reliability for users that wants a high level of confidence in the cron jobs they need to run.\nManually bootstrapping a Dkron cluster does not rely on additional tooling, but does require operator participation in the cluster formation process. When bootstrapping, Dkron servers and clients must be started and informed with the address of at least one Dkron server.\nAs you can tell, this creates a chicken-and-egg problem where one server must first be fully bootstrapped and configured before the remaining servers and clients can join the cluster. This requirement can add additional provisioning time as well as ordered dependencies during provisioning.\nFirst, we bootstrap a single Dkron server and capture its IP address. After we have that nodes IP address, we place this address in the configuration.\n First bootstrap a node with a configuration like this:  # dkron.yml server: true bootstrap-expect: 1  Then stop the bootstrapped server and capture the server IP address.\n  To form a cluster, configure server nodes (including the bootstrapped server) with the address of its peers as in the following example:\n  # dkron.yml server: true bootstrap-expect: 3 join: - 10.19.3.9 - 10.19.4.64 - 10.19.7.215 "
},
{
	"uri": "/pro/commercial-faq/",
	"title": "Commercial FAQ",
	"tags": [],
	"description": "",
	"content": "What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers.\nIs there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you.\nCan I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price.\nWhat is the license? See COMM-LICENSE.\nHow does Pro licensing work? Every organization running Dkron Pro on its own servers must have a license. There\u0026rsquo;s no limit to the number of servers or environments used by that organization.\nWhat happens if my subscription lapses? You must have an active subscription to run Dkron Pro. After a one week grace period, you\u0026rsquo;ll lose access to the package repository and priority support. You won\u0026rsquo;t get any more updates or bug fixes and apt-get install dkron-pro won\u0026rsquo;t work anymore.\nCan I distribute Dkron Pro to my customers? This is a common requirement for \u0026ldquo;on-site installs\u0026rdquo; or \u0026ldquo;appliances\u0026rdquo; sold to large corporations.\nThe standard license is only appropriate for SaaS usage as it does not allow distribution. Dkron Pro have an Appliance license option which does allow you to distribute them. The Appliance license is $7,500/yr for Pro. It allows you to distribute the Pro binaries as part of your application and each of your customers to run Dkron Pro as part of your application only. Email support@distrib.works to purchase.\nCan you transfer a license? Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@example.com -\u0026gt; tech@example.com) but only for the same domain. It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee\u0026rsquo;s email address.\nWhat does the license require me to do? Your purchase gets you unique access credentials for downloading the Pro packages. The license agreement requires you to keep these access credentials private. If we find your access credentials are ever publicized:\n We\u0026rsquo;ll send you a warning email with details. You need to remove the content and send a new email address so we can generate new credentials for you. The old credentials will stop working immediately so you\u0026rsquo;ll need to update your apps. If your credentials are publicized a second time, we reserve the right to permanently remove access (but won\u0026rsquo;t unless it\u0026rsquo;s really egregious - sloppy contractors happen).  Can I get a refund? Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it\u0026rsquo;s not a problem. Email support@distrib.works.\nHow do I update my credit card info? If you purchased Dkron Pro (settings) with a credit card, log into Gumroad with your email address, click the Settings, enter your card info and hit Save. Follow instructions in Gumroad docs https://help.gumroad.com/how-do-i-update-my-credit-card-information I can\u0026rsquo;t provide support for the Gumroad website and don\u0026rsquo;t have the ability to edit customer info - if you can\u0026rsquo;t log in or change your credit card, you can always let your current subscription expire and purchase a new subscription.\nCan I request a change to the license terms? Dkron Pro customers purchasing the Appliance license can ask for changes to the terms and conditions.\nIf you don\u0026rsquo;t need the Appliance license but wants to ask for changes to the terms and conditions you will need to purchase a Dkron Pro standard license per production server.\nEmail your concerns and we can negotiate something.\nCan I pay via invoice and purchase order? Dkron Pro is credit card only, no exceptions.\nContact Info Distributed Works\nAll billing/support inquiries: support@distrib.works\nPhone: not available\n"
},
{
	"uri": "/v1.2/pro/commercial-faq/",
	"title": "Commercial FAQ",
	"tags": [],
	"description": "",
	"content": "What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers.\nIs there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you.\nCan I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price.\nWhat is the license? See COMM-LICENSE.\nHow does Pro licensing work? Every organization running Dkron Pro on its own servers must have a license. There\u0026rsquo;s no limit to the number of servers or environments used by that organization.\nWhat happens if my subscription lapses? You must have an active subscription to run Dkron Pro. After a one week grace period, you\u0026rsquo;ll lose access to the package repository and priority support. You won\u0026rsquo;t get any more updates or bug fixes and \u0026lsquo;apt-get install dkron-pro\u0026rsquo; won\u0026rsquo;t work anymore.\nCan I distribute Dkron Pro to my customers? This is a common requirement for \u0026ldquo;on-site installs\u0026rdquo; or \u0026ldquo;appliances\u0026rdquo; sold to large corporations.\nThe standard license is only appropriate for SaaS usage as it does not allow distribution. Dkron Pro have an Appliance license option which does allow you to distribute them. The Appliance license is $3,950/yr for Pro. It allows you to distribute the Pro binaries as part of your application and each of your customers to run Dkron Pro as part of your application only. Email support@distrib.works to purchase.\nCan you transfer a license? Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@example.com -\u0026gt; tech@example.com) but only for the same domain. It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee\u0026rsquo;s email address.\nWhat does the license require me to do? Your purchase gets you unique access credentials for downloading the Pro packages. The license agreement requires you to keep these access credentials private. If we find your access credentials are ever publicized:\n We\u0026rsquo;ll send you a warning email with details. You need to remove the content and send a new email address so we can generate new credentials for you. The old credentials will stop working immediately so you\u0026rsquo;ll need to update your apps. If your credentials are publicized a second time, we reserve the right to permanently remove access (but won\u0026rsquo;t unless it\u0026rsquo;s really egregious - sloppy contractors happen).  Can I get a refund? Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it\u0026rsquo;s not a problem. Email support@distrib.works.\nHow do I update my credit card info? If you purchased Dkron Pro (settings) with a credit card, log into Gumroad with your email address, click the Settings, enter your card info and hit Save. Follow instructions in Gumroad docs https://help.gumroad.com/how-do-i-update-my-credit-card-information I can\u0026rsquo;t provide support for the Gumroad website and don\u0026rsquo;t have the ability to edit customer info - if you can\u0026rsquo;t log in or change your credit card, you can always let your current subscription expire and purchase a new subscription.\nCan I request a change to the license terms? Dkron Pro purchasing the Appliance license can ask for changes to the terms and conditions. Email your concerns and we can negotiate something.\nCan I pay via invoice and purchase order? Dkron Pro is credit card only, no exceptions.\nContact Info Distributed Works\nAll billing/support inquiries: support@distrib.works\nPhone: not available\n"
},
{
	"uri": "/v2.0/pro/commercial-faq/",
	"title": "Commercial FAQ",
	"tags": [],
	"description": "",
	"content": "What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers.\nIs there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you.\nCan I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price.\nWhat is the license? See COMM-LICENSE.\nHow does Pro licensing work? Every organization running Dkron Pro on its own servers must have a license. There\u0026rsquo;s no limit to the number of servers or environments used by that organization.\nWhat happens if my subscription lapses? You must have an active subscription to run Dkron Pro. After a one week grace period, you\u0026rsquo;ll lose access to the package repository and priority support. You won\u0026rsquo;t get any more updates or bug fixes and apt-get install dkron-pro won\u0026rsquo;t work anymore.\nCan I distribute Dkron Pro to my customers? This is a common requirement for \u0026ldquo;on-site installs\u0026rdquo; or \u0026ldquo;appliances\u0026rdquo; sold to large corporations.\nThe standard license is only appropriate for SaaS usage as it does not allow distribution. Dkron Pro have an Appliance license option which does allow you to distribute them. The Appliance license is $7,500/yr for Pro. It allows you to distribute the Pro binaries as part of your application and each of your customers to run Dkron Pro as part of your application only. Email support@distrib.works to purchase.\nCan you transfer a license? Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@example.com -\u0026gt; tech@example.com) but only for the same domain. It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee\u0026rsquo;s email address.\nWhat does the license require me to do? Your purchase gets you unique access credentials for downloading the Pro packages. The license agreement requires you to keep these access credentials private. If we find your access credentials are ever publicized:\n We\u0026rsquo;ll send you a warning email with details. You need to remove the content and send a new email address so we can generate new credentials for you. The old credentials will stop working immediately so you\u0026rsquo;ll need to update your apps. If your credentials are publicized a second time, we reserve the right to permanently remove access (but won\u0026rsquo;t unless it\u0026rsquo;s really egregious - sloppy contractors happen).  Can I get a refund? Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it\u0026rsquo;s not a problem. Email support@distrib.works.\nHow do I update my credit card info? If you purchased Dkron Pro (settings) with a credit card, log into Gumroad with your email address, click the Settings, enter your card info and hit Save. Follow instructions in Gumroad docs https://help.gumroad.com/how-do-i-update-my-credit-card-information I can\u0026rsquo;t provide support for the Gumroad website and don\u0026rsquo;t have the ability to edit customer info - if you can\u0026rsquo;t log in or change your credit card, you can always let your current subscription expire and purchase a new subscription.\nCan I request a change to the license terms? Dkron Pro purchasing the Appliance license can ask for changes to the terms and conditions. Email your concerns and we can negotiate something.\nCan I pay via invoice and purchase order? Dkron Pro is credit card only, no exceptions.\nContact Info Distributed Works\nAll billing/support inquiries: support@distrib.works\nPhone: not available\n"
},
{
	"uri": "/pro/commercial-support/",
	"title": "Commercial Support",
	"tags": [],
	"description": "",
	"content": "Dkron offers only community support. Dkro Pro offers priority support via email.\nPriority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not application integration or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n"
},
{
	"uri": "/v1.2/pro/commercial-support/",
	"title": "Commercial Support",
	"tags": [],
	"description": "",
	"content": "Dkron offers only community support. Dkro Pro offers priority support via email.\nPriority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not the application or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n"
},
{
	"uri": "/v2.0/pro/commercial-support/",
	"title": "Commercial Support",
	"tags": [],
	"description": "",
	"content": "Dkron offers only community support. Dkro Pro offers priority support via email.\nPriority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not application integration or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n"
},
{
	"uri": "/usage/concurrency/",
	"title": "Concurrency",
	"tags": [],
	"description": "",
	"content": "Concurrency Jobs can be configured to allow overlapping executions or forbid them.\nConcurrency property accepts two option:\n allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule.  Example:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; } "
},
{
	"uri": "/v1.2/usage/concurrency/",
	"title": "Concurrency",
	"tags": [],
	"description": "",
	"content": "Concurrency Jobs can be configured to allow overlapping executions or forbid them.\nConcurrency property accepts two option:\n allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule.  Example:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; } "
},
{
	"uri": "/v2.0/usage/concurrency/",
	"title": "Concurrency",
	"tags": [],
	"description": "",
	"content": "Concurrency Jobs can be configured to allow overlapping executions or forbid them.\nConcurrency property accepts two option:\n allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule.  Example:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;concurrency\u0026#34;: \u0026#34;forbid\u0026#34; } "
},
{
	"uri": "/basics/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuration sources Settings can be specified in three ways (in order of precedence):\n Command line arguments. Environment variables starting with DKRON_ dkron.yml config file  Config file location Config file will be loaded from the following paths:\n /etc/dkron $HOME/.dkron ./config  Config file example # Dkron example configuration file # server: false # bootstrap-expect: 3 # data-dir: dkron.data # log-level: debug # tags: # dc: east # encrypt: a-valid-key-generated-with-dkron-keygen # retry-join: # - 10.0.0.1 # - 10.0.0.2 # - 10.0.0.3 # raft-multiplier: 1 # webhook-url: https://hooks.slack.com/services/XXXXXX/XXXXXXX/XXXXXXXXXXXXXXXXXXXX # webhook-payload: \u0026#34;payload={\\\u0026#34;text\\\u0026#34;: \\\u0026#34;{{.Report}}\\\u0026#34;, \\\u0026#34;channel\\\u0026#34;: \\\u0026#34;#foo\\\u0026#34;}\u0026#34; # webhook-headers: Content-Type:application/x-www-form-urlencoded # mail-host: email-smtp.eu-west-1.amazonaws.com # mail-port: 25 # mail-username\u0026#34;: mailuser # mail-password\u0026#34;: mailpassword # mail-from\u0026#34;: cron@example.com # mail-subject_prefix: [Dkron] SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron version\t- Show version  "
},
{
	"uri": "/pro/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters.\nCommand line options  --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates  "
},
{
	"uri": "/v1.2/basics/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuration sources Settings can be specified in three ways (in order of precedence):\n Command line arguments. Environment variables starting with DKRON_ dkron.json config file  Config file example # Dkron example configuration file # backend: etcd # backend-machine: 127.0.0.1:2379 # server: false # log-level: debug # tags: # role: web # datacenter: east # keyspace: dkron # encrypt: a-valid-key-generated-with-dkron-keygen # join: # - 10.0.0.1 # - 10.0.0.2 # - 10.0.0.3 # webhook-url: https://hooks.slack.com/services/XXXXXX/XXXXXXX/XXXXXXXXXXXXXXXXXXXX # webhook-payload: \u0026#34;payload={\\\u0026#34;text\\\u0026#34;: \\\u0026#34;{{.Report}}\\\u0026#34;, \\\u0026#34;channel\\\u0026#34;: \\\u0026#34;#foo\\\u0026#34;}\u0026#34; # webhook-headers: Content-Type:application/x-www-form-urlencoded # mail-host: email-smtp.eu-west-1.amazonaws.com # mail-port: 25 # mail-username\u0026#34;: mailuser # mail-password\u0026#34;: mailpassword # mail-from\u0026#34;: cron@example.com # mail-subject_prefix: [Dkron] SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron version\t- Show version  "
},
{
	"uri": "/v1.2/pro/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters.\nCommand line options  --etcd-config-file-path - Etcd node config --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates  "
},
{
	"uri": "/v2.0/basics/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuration sources Settings can be specified in three ways (in order of precedence):\n Command line arguments. Environment variables starting with DKRON_ dkron.yml config file  Config file location Config file will be loaded from the following paths:\n /etc/dkron $HOME/.dkron ./config  Config file example # Dkron example configuration file # server: false # bootstrap-expect: 3 # data-dir: dkron.data # log-level: debug # tags: # dc: east # encrypt: a-valid-key-generated-with-dkron-keygen # retry-join: # - 10.0.0.1 # - 10.0.0.2 # - 10.0.0.3 # raft-multiplier: 1 # webhook-url: https://hooks.slack.com/services/XXXXXX/XXXXXXX/XXXXXXXXXXXXXXXXXXXX # webhook-payload: \u0026#34;payload={\\\u0026#34;text\\\u0026#34;: \\\u0026#34;{{.Report}}\\\u0026#34;, \\\u0026#34;channel\\\u0026#34;: \\\u0026#34;#foo\\\u0026#34;}\u0026#34; # webhook-headers: Content-Type:application/x-www-form-urlencoded # mail-host: email-smtp.eu-west-1.amazonaws.com # mail-port: 25 # mail-username\u0026#34;: mailuser # mail-password\u0026#34;: mailpassword # mail-from\u0026#34;: cron@example.com # mail-subject_prefix: [Dkron] SEE ALSO  dkron agent\t- Start a dkron agent dkron doc\t- Generate Markdown documentation for the Dkron CLI. dkron keygen\t- Generates a new encryption key dkron version\t- Show version  "
},
{
	"uri": "/v2.0/pro/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "Configuration Dkron Pro uses the same parameters as Dkron OSS and add some extra parameters.\nCommand line options  --username - Authentication username --password - Authentication password --cert-file - Path to the client server TLS cert file --key-file - Path to the client server TLS key file --client-crl-file - Path to the client certificate revocation list file --trusted-ca-file - Path to the client server TLS trusted CA cert file --client-cert-auth - Enable client cert authentication --auto-tls - Client TLS using generated certificates  "
},
{
	"uri": "/pro/failover/",
	"title": "Cross region failover",
	"tags": [],
	"description": "",
	"content": "Dkron Pro can run federated in failover mode, this allows to have two clusters running in different regions and configure one of the clusters in an active-passive fashion, doing a failover in case the active cluster dies.\nThis feature is experimental and should be handled with care.\n "
},
{
	"uri": "/v2.0/pro/failover/",
	"title": "Cross region failover",
	"tags": [],
	"description": "",
	"content": "Dkron Pro can run federated in failover mode, this allows to have two clusters running in different regions and configure one of the clusters in an active-passive fashion, doing a failover in case the active cluster dies.\nThis feature is experimental and should be handled with care.\n "
},
{
	"uri": "/products/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": " Dkron Pro Improved security, features and reliability for your scheduled jobs  Buy      Get additional features and commercial support from the creator of Dkron\n Key features Security  Pro has enhanced security using industry standard SSL encryption for communication between all components of the application, the embedded storage engine and nodes.\nYou can also enable basic authentication to restrict access to the WebUI and the API.\nPro plugins  Do you need to store job output in Elasticsearch? Do you need to run docker based jobs?\nDkron Pro adds some commercially supported plugins ready to cover your needs.\nSupport  Priority support from the author\nWorkload automation is a critical process in your business. Guarantee direct access to a Dkron expert. Your subscription gives you priority support for any unforeseen issues.\n    Product details FEATURES  Dkron Pro contains the following functionality:   Multi-region support   Full SSL encryption   Elasticsearch processor   Docker executor   AWS ECS executor   Advanced email processor   WebUI and API authorization   DOCUMENTATION Detailed documentation about configuring and using each feature can be found in the Dkron docs site. Read the Commercial FAQ for further details.\nSUPPORT Your subscription gives you priority email support for any issues which might arise.\nSales of Dkron Pro also benefit the community by ensuring that Dkron itself will remain well supported for the foreseeable future.\nINSTALLATION When you buy Dkron Pro, a custom URL associated with your email address will be sent to you. You use this URL to install the package corresponding to your architecture. You configure and use Dkron Pro exactly like you would Dkron.\nPro tip : use a mailing list for your email when purchasing to ensure you get critical email updates, even if employees leave the company.\nUPGRADES Dkron Pro will receive bug fixes and new functionality over time. All upgrades will be free to subscribers with a simple package upgrade. See the changelog for more detail.\nLICENSING Dkron is available under the terms of the GNU LGPLv3 license.\nIn addition to its useful functionality, buying Dkron Pro grants your organization a Dkron commercial license instead of the GNU LGPL, avoiding any legal issues your lawyers might raise. Please see the Commercial FAQ for further detail on licensing including options for distributing Dkron Pro with your own products.\n   "
},
{
	"uri": "/v2.0/products/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": " Dkron Pro Improved security, features and reliability for your scheduled jobs  Buy      Get additional features and commercial support from the creator of Dkron\n Key features Security  Pro has enhanced security using industry standard SSL encryption for communication between all components of the application, the embedded storage engine and nodes.\nYou can also enable basic authentication to restrict access to the WebUI and the API.\nPro plugins  Do you need to store job output in Elasticsearch? Do you need to run docker based jobs?\nDkron Pro adds some commercially supported plugins ready to cover your needs.\nSupport  Priority support from the author\nWorkload automation is a critical process in your business. Guarantee direct access to a Dkron expert. Your subscription gives you priority support for any unforeseen issues.\n    Product details FEATURES  Dkron Pro contains the following functionality:   Multi-region support   Full SSL encryption   Elasticsearch processor   Docker executor   AWS ECS executor   Advanced email processor   WebUI and API authorization   DOCUMENTATION Detailed documentation about configuring and using each feature can be found in the Dkron docs site. Read the Commercial FAQ for further details.\nSUPPORT Your subscription gives you priority email support for any issues which might arise.\nSales of Dkron Pro also benefit the community by ensuring that Dkron itself will remain well supported for the foreseeable future.\nINSTALLATION When you buy Dkron Pro, a custom URL associated with your email address will be sent to you. You use this URL to install the package corresponding to your architecture. You configure and use Dkron Pro exactly like you would Dkron.\nPro tip : use a mailing list for your email when purchasing to ensure you get critical email updates, even if employees leave the company.\nUPGRADES Dkron Pro will receive bug fixes and new functionality over time. All upgrades will be free to subscribers with a simple package upgrade. See the changelog for more detail.\nLICENSING Dkron is available under the terms of the GNU LGPLv3 license.\nIn addition to its useful functionality, buying Dkron Pro grants your organization a Dkron commercial license instead of the GNU LGPL, avoiding any legal issues your lawyers might raise. Please see the Commercial FAQ for further detail on licensing including options for distributing Dkron Pro with your own products.\n   "
},
{
	"uri": "/intro/dkron_vs_other_software/",
	"title": "Dkron vs. Other Software",
	"tags": [],
	"description": "",
	"content": "Dkron vs. Chronos Airbnb\u0026rsquo;s Chronos is a job scheduler that is similar to dkron, it\u0026rsquo;s distributed and fault tolerant thanks to the use of Zookeeper and Apache Mesos.\nIf you don\u0026rsquo;t have/want to run a Mesos cluster and deal with the not easy configuration and maintenance of Zookeeper and you want something lighter, Dkron could help you.\nDkron vs. Rundeck Rundeck is a popular and mature platform to automate operations and schedule jobs.\nIt has cool features:\n Agentless Permissions and auditing  It\u0026rsquo;s written in Java and it\u0026rsquo;s not trivial to setup right.\nIt uses a central database to store job execution results and configuration data, that makes it vulnerable to failures, and you need to take care of providing an HA environment for the database yourself, and that\u0026rsquo;s not an easy task to do with Rundeck\u0026rsquo;s supported databases.\nDkron lacks some of its features but it\u0026rsquo;s lightweight and fault-tolerant out-of-the-box.\n"
},
{
	"uri": "/v1.2/intro/dkron_vs_other_software/",
	"title": "Dkron vs. Other Software",
	"tags": [],
	"description": "",
	"content": "Dkron vs. Chronos Airbnb\u0026rsquo;s Chronos is a job scheduler that is similar to dkron, it\u0026rsquo;s distributed and fault tolerant thanks to the use of Zookeeper and Apache Mesos.\nIf you don\u0026rsquo;t have/want to run a Mesos cluster and deal with the not easy configuration and maintenance of Zookeeper and you want something lighter, Dkron could help you.\nDkron vs. Rundeck Rundeck is a popular and mature platform to automate operations and schedule jobs.\nIt has cool features:\n Agentless Permissions and auditing  It\u0026rsquo;s written in Java and it\u0026rsquo;s not trivial to setup right.\nIt uses a central database to store job execution results and configuration data, that makes it vulnerable to failures, and you need to take care of providing an HA environment for the database yourself, and that\u0026rsquo;s not an easy task to do with Rundeck\u0026rsquo;s supported databases.\nDkron lacks some of its features but it\u0026rsquo;s lightweight and fault-tolerant out-of-the-box.\n"
},
{
	"uri": "/v2.0/intro/dkron_vs_other_software/",
	"title": "Dkron vs. Other Software",
	"tags": [],
	"description": "",
	"content": "Dkron vs. Chronos Airbnb\u0026rsquo;s Chronos is a job scheduler that is similar to dkron, it\u0026rsquo;s distributed and fault tolerant thanks to the use of Zookeeper and Apache Mesos.\nIf you don\u0026rsquo;t have/want to run a Mesos cluster and deal with the not easy configuration and maintenance of Zookeeper and you want something lighter, Dkron could help you.\nDkron vs. Rundeck Rundeck is a popular and mature platform to automate operations and schedule jobs.\nIt has cool features:\n Agentless Permissions and auditing  It\u0026rsquo;s written in Java and it\u0026rsquo;s not trivial to setup right.\nIt uses a central database to store job execution results and configuration data, that makes it vulnerable to failures, and you need to take care of providing an HA environment for the database yourself, and that\u0026rsquo;s not an easy task to do with Rundeck\u0026rsquo;s supported databases.\nDkron lacks some of its features but it\u0026rsquo;s lightweight and fault-tolerant out-of-the-box.\n"
},
{
	"uri": "/pro/executors/docker/",
	"title": "Docker executor",
	"tags": [],
	"description": "",
	"content": "Docker executor can launch docker based cron jobs using the docker command of the target node.\nThis executor needs a recent version of docker to be available and configured in the target node.\nConfiguration To run a docker job create a job config with the docker executor as in this example:\n{ \u0026#34;executor\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;alpine\u0026#34;, //docker image to use \u0026#34;volumes\u0026#34;: \u0026#34;/logs:/var/log/\u0026#34;, //comma separated list of volume mappings \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34;, //command to pass to run on container \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34; //environment variables to pass to the container } } "
},
{
	"uri": "/v1.2/pro/executors/docker/",
	"title": "Docker executor",
	"tags": [],
	"description": "",
	"content": "Docker executor can launch docker based cron jobs using the docker command of the target node.\nThis executor needs a recent version of docker to be available and configured in the target node.\nConfiguration To run a docker job create a job config with the docker executor as in this example:\n{ \u0026#34;executor\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;alpine\u0026#34;, //docker image to use \u0026#34;volumes\u0026#34;: \u0026#34;/logs:/var/log/\u0026#34;, //comma separated list of volume mappings \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34;, //command to pass to run on container \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34; //environment variables to pass to the container } } "
},
{
	"uri": "/v2.0/pro/executors/docker/",
	"title": "Docker executor",
	"tags": [],
	"description": "",
	"content": "Docker executor can launch docker based cron jobs using the docker command of the target node.\nThis executor needs a recent version of docker to be available and configured in the target node.\nConfiguration To run a docker job create a job config with the docker executor as in this example:\n{ \u0026#34;executor\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;alpine\u0026#34;, //docker image to use \u0026#34;volumes\u0026#34;: \u0026#34;/logs:/var/log/\u0026#34;, //comma separated list of volume mappings \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34;, //command to pass to run on container \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34; //environment variables to pass to the container } } "
},
{
	"uri": "/pro/processors/elasticsearch/",
	"title": "Elasticsearch processor",
	"tags": [],
	"description": "",
	"content": "The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node.\nThe output logs of the job execution will be stored in the indicated ES instace.\nConfiguration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } } "
},
{
	"uri": "/v1.2/pro/processors/elasticsearch/",
	"title": "Elasticsearch processor",
	"tags": [],
	"description": "",
	"content": "The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node.\nThe output logs of the job execution will be stored in the indicated ES instace.\nConfiguration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } } "
},
{
	"uri": "/v2.0/pro/processors/elasticsearch/",
	"title": "Elasticsearch processor",
	"tags": [],
	"description": "",
	"content": "The Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node.\nThe output logs of the job execution will be stored in the indicated ES instace.\nConfiguration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } } "
},
{
	"uri": "/pro/processors/email/",
	"title": "Email processor",
	"tags": [],
	"description": "",
	"content": "The Email processor provides flexibility to job email notifications.\nConfiguration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers.\nExample:\nprovider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.com, owner@mycompany.com\u0026#34;, \u0026#34;onSuccess\u0026#34;: \u0026#34;true\u0026#34; } } } By default the email procesor doesn\u0026rsquo;t send emails on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/v1.2/pro/processors/email/",
	"title": "Email processor",
	"tags": [],
	"description": "",
	"content": "The Email processor provides flexibility to job email notifications.\nConfiguration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers.\nExample:\nprovider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.com, owner@mycompany.com\u0026#34;, \u0026#34;onSuccess\u0026#34;: true } } } By default the email procesor doesn\u0026rsquo;t send emails on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/v2.0/pro/processors/email/",
	"title": "Email processor",
	"tags": [],
	"description": "",
	"content": "The Email processor provides flexibility to job email notifications.\nConfiguration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers.\nExample:\nprovider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.com, owner@mycompany.com\u0026#34;, \u0026#34;onSuccess\u0026#34;: \u0026#34;true\u0026#34; } } } By default the email procesor doesn\u0026rsquo;t send emails on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/usage/storage/",
	"title": "Embedded storage",
	"tags": [],
	"description": "",
	"content": "Dkron has an embedded distributed KV store engine based on BuntDB. This works out of the box on each dkron server.\nThis ensures a dead easy install and setup, basically run dkron and you will have a full working node.\n"
},
{
	"uri": "/v1.2/pro/storage/",
	"title": "Embedded storage",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started.\nThis ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron.\n"
},
{
	"uri": "/v2.0/usage/storage/",
	"title": "Embedded storage",
	"tags": [],
	"description": "",
	"content": "Dkron has an embedded distributed KV store engine based on BadgerDB. This works out of the box on each dkron server.\nThis ensures a dead easy install and setup, basically run dkron and you will have a full working node.\n"
},
{
	"uri": "/pro/encryption/",
	"title": "Encryption",
	"tags": [],
	"description": "",
	"content": "SSL encryption is used for communicating dkron pro nodes. Also if client auth is enabled. This means that no other software running on your local network will be able to talk to dkron servers.\nThis ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\nSSL encryption is enabled by default in Dkron Pro and can not be disabled, you don\u0026rsquo;t need to do nothing to use it.\nBy default Dkron Pro runs with automatically generated SSL certificates, this is enough for using it in a trusted environment but to have a better grade of confidence, it is recommended to run Dkron Pro with custom SSL certificates.\nFollow this tutorial to generate autosigned SSL certificates for your instances.\nYou don\u0026rsquo;t need a client certificate for Dkron server, just add \u0026ldquo;client auth\u0026rdquo; usage to your server cert.\n # dkron.yaml auto-tls: false # Set to false to use custom certs key-file: server-key.pem cert-file: server.pem trusted-ca-file: ca.pem client-cert-auth: true # Enable it to only allow certs signed by the same CA "
},
{
	"uri": "/v1.2/pro/encryption/",
	"title": "Encryption",
	"tags": [],
	"description": "",
	"content": "SSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also if client auth is enabled, only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron\u0026rsquo;s etcd server.\nThis ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\nSSL encryption is enabled by default in Dkron Pro and can not be disabled, you don\u0026rsquo;t need to do nothing to use it.\nBy default Dkron Pro runs with automatically generated SSL certificates, this is enough for using it in a trusted environment but to have a better grade of confidence, it is recommended to run Dkron Pro with custom SSL certificates.\nFollow this tutorial to generate autosigned SSL certificates for your instances.\nYou don\u0026rsquo;t need a client certificate for Dkron server, just add \u0026ldquo;client auth\u0026rdquo; usage to your server cert.\n # dkron.yaml auto-tls: false # Set to false to use custom certs key-file: server-key.pem cert-file: server.pem trusted-ca-file: ca.pem client-cert-auth: true # Enable it to only allow certs signed by the same CA "
},
{
	"uri": "/v2.0/pro/encryption/",
	"title": "Encryption",
	"tags": [],
	"description": "",
	"content": "SSL encryption is used for communicating dkron pro nodes. Also if client auth is enabled. This means that no other software running on your local network will be able to talk to dkron servers.\nThis ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\nSSL encryption is enabled by default in Dkron Pro and can not be disabled, you don\u0026rsquo;t need to do nothing to use it.\nBy default Dkron Pro runs with automatically generated SSL certificates, this is enough for using it in a trusted environment but to have a better grade of confidence, it is recommended to run Dkron Pro with custom SSL certificates.\nFollow this tutorial to generate autosigned SSL certificates for your instances.\nYou don\u0026rsquo;t need a client certificate for Dkron server, just add \u0026ldquo;client auth\u0026rdquo; usage to your server cert.\n # dkron.yaml auto-tls: false # Set to false to use custom certs key-file: server-key.pem cert-file: server.pem trusted-ca-file: ca.pem client-cert-auth: true # Enable it to only allow certs signed by the same CA "
},
{
	"uri": "/pro/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": " AWS ECS Executor\nThe ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output. To configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS. To allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:\n  Docker executor\nDocker executor can launch docker based cron jobs using the docker command of the target node. This executor needs a recent version of docker to be available and configured in the target node. Configuration To run a docker job create a job config with the docker executor as in this example: { \u0026#34;executor\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;alpine\u0026#34;, //docker image to use \u0026#34;volumes\u0026#34;: \u0026#34;/logs:/var/log/\u0026#34;, //comma separated list of volume mappings \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34;, //command to pass to run on container \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34; //environment variables to pass to the container } }   "
},
{
	"uri": "/v1.2/pro/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/v2.0/pro/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": " AWS ECS Executor\nThe ECS exeutor is capable of launching tasks in ECS clusters, then listen to a stream of CloudWatch Logs and return the output. To configure a job to be run in ECS, the executor needs a JSON Task definition template or an already defined task in ECS. To allow the ECS Task runner to run tasks, the machine running Dkron needs to have the appropriate permissions configured in AWS IAM:\n  Docker executor\nDocker executor can launch docker based cron jobs using the docker command of the target node. This executor needs a recent version of docker to be available and configured in the target node. Configuration To run a docker job create a job config with the docker executor as in this example: { \u0026#34;executor\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;image\u0026#34;: \u0026#34;alpine\u0026#34;, //docker image to use \u0026#34;volumes\u0026#34;: \u0026#34;/logs:/var/log/\u0026#34;, //comma separated list of volume mappings \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from dkron\\\u0026#34;\u0026#34;, //command to pass to run on container \u0026#34;env\u0026#34;: \u0026#34;ENVIRONMENT=variable\u0026#34; //environment variables to pass to the container } }   "
},
{
	"uri": "/usage/processors/file/",
	"title": "File Processor",
	"tags": [],
	"description": "",
	"content": "File processor saves the execution output to a single log file in the specified directory\nConfiguration Parameters\nlog_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: \u0026#34;true\u0026#34; } } } "
},
{
	"uri": "/v1.2/usage/processors/file/",
	"title": "File Processor",
	"tags": [],
	"description": "",
	"content": "File processor saves the execution output to a single log file in the specified directory\nConfiguration Parameters\nlog_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: true } } } "
},
{
	"uri": "/v2.0/usage/processors/file/",
	"title": "File Processor",
	"tags": [],
	"description": "",
	"content": "File processor saves the execution output to a single log file in the specified directory\nConfiguration Parameters\nlog_dir: Path to the location where the log files will be saved forward: Forward log output to the next processor Example\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello files\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;files\u0026#34;: { \u0026#34;log_dir\u0026#34;: \u0026#34;/var/log/mydir\u0026#34;, \u0026#34;forward\u0026#34;: true } } } "
},
{
	"uri": "/usage/executors/http/",
	"title": "HTTP Executor",
	"tags": [],
	"description": "",
	"content": "HTTP executor can send a request to an HTTP endpoint\nConfiguration Params:\nmethod: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty tlsNoVerifyPeer: false (default) or true. If true, disables verification of the remote SSL certificate's validity. tlsCertificateFile: Path to the PEM file containing the client certificate. Optional. tlsCertificateKeyFile: Path to the PEM file containing the client certificate private key. Optional. tlsRootCAsFile: Path to the PEM file containing certificates to use as root CAs. Optional. Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://example.com\u0026#34;, \u0026#34;headers\u0026#34;: \u0026#34;[]\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;expectCode\u0026#34;: \u0026#34;200\u0026#34;, \u0026#34;expectBody\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;debug\u0026#34;: \u0026#34;true\u0026#34; } } "
},
{
	"uri": "/v1.2/usage/executors/http/",
	"title": "HTTP Executor",
	"tags": [],
	"description": "",
	"content": "HTTP executor can send a request to an HTTP endpoint\nConfiguration Params:\nmethod: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://example.com\u0026#34;, \u0026#34;headers\u0026#34;: \u0026#34;[]\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;expectCode\u0026#34;: \u0026#34;200\u0026#34;, \u0026#34;expectBody\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;debug\u0026#34;: \u0026#34;true\u0026#34; } } "
},
{
	"uri": "/v2.0/usage/executors/http/",
	"title": "HTTP Executor",
	"tags": [],
	"description": "",
	"content": "HTTP executor can send a request to an HTTP endpoint\nConfiguration Params:\nmethod: Request method in uppercase url: Request url headers: Json string, such as \u0026quot;[\\\u0026quot;Content-Type: application/json\\\u0026quot;]\u0026quot; body: POST body timeout: Request timeout, unit seconds expectCode: Expect response code, such as 200,206 expectBody: Expect response body, support regexp, such as /success/ debug: Debug option, will log everything when this option is not empty tlsNoVerifyPeer: false (default) or true. If true, disables verification of the remote SSL certificate's validity. tlsCertificateFile: Path to the PEM file containing the client certificate. Optional. tlsCertificateKeyFile: Path to the PEM file containing the client certificate private key. Optional. tlsRootCAsFile: Path to the PEM file containing certificates to use as root CAs. Optional. Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://example.com\u0026#34;, \u0026#34;headers\u0026#34;: \u0026#34;[]\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;30\u0026#34;, \u0026#34;expectCode\u0026#34;: \u0026#34;200\u0026#34;, \u0026#34;expectBody\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;debug\u0026#34;: \u0026#34;true\u0026#34; } } "
},
{
	"uri": "/v1.2/usage/internals/",
	"title": "Internals",
	"tags": [],
	"description": "",
	"content": "This document is a WIP, it\u0026rsquo;s intended to describe the reasons that lead to design decisions in Dkron.\nExecution results Dkron store the result of each job execution in each node.\nEvery time dkron executes a job it assigns it an execution group, generating a new uuid and send a serf query to target machines and waits for a response.\nEach target machine that will run the job, then responds with an execution object saying it started to run the job.\nThis allows dkron to know how many machines will be running the job.\nThe design takes into account the differences of how the different storage backends work.\nDue to this issue https://github.com/docker/libkv/issues/20 executions are grouped using the group id in the execution object.\nExecutions commands output When a node has finished executing a job it gathers the output of the executed command and sends it back to the a server using an RPC call. This is designed after two main reasons:\n  Scallability, in case of thousands of nodes responding to job the responses are sent to dkron servers in an evenly way selecting a random Dkron server of the ones that are available at the moment and send the response. In the future, Dkron should retry sending the command result with an exponential backoff.\n  Due to the limitations of Serf the queries payload can\u0026rsquo;t be bigger that 1KB, this renders impossible to send a minimal command output togheter with the execution metadata.\n  "
},
{
	"uri": "/usage/chaining/",
	"title": "Job chaining",
	"tags": [],
	"description": "",
	"content": "Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job.\nThe dependent job will be executed after the main job finished a successful execution.\nChild jobs schedule property will be ignored if it\u0026rsquo;s present.\nTake into account that parent jobs must be created before any child job.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; } } { \u0026#34;name\u0026#34;: \u0026#34;child_job\u0026#34;, \u0026#34;parent_job\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from child\\\u0026#34;\u0026#34; } } "
},
{
	"uri": "/v1.2/usage/chaining/",
	"title": "Job chaining",
	"tags": [],
	"description": "",
	"content": "Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job.\nThe dependent job will be executed after the main job finished a successful execution.\nChild jobs schedule property will be ignored if it\u0026rsquo;s present.\nTake into account that parent jobs must be created before any child job.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; } } { \u0026#34;name\u0026#34;: \u0026#34;child_job\u0026#34;, \u0026#34;parent_job\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from child\\\u0026#34;\u0026#34; } } "
},
{
	"uri": "/v2.0/usage/chaining/",
	"title": "Job chaining",
	"tags": [],
	"description": "",
	"content": "Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job.\nThe dependent job will be executed after the main job finished a successful execution.\nChild jobs schedule property will be ignored if it\u0026rsquo;s present.\nTake into account that parent jobs must be created before any child job.\nExample:\n{ \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; } } { \u0026#34;name\u0026#34;: \u0026#34;child_job\u0026#34;, \u0026#34;parent_job\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from child\\\u0026#34;\u0026#34; } } "
},
{
	"uri": "/usage/metatags/",
	"title": "Job metadata",
	"tags": [],
	"description": "",
	"content": "Job metadata Jobs can have an optional extra property field called metadata that allows to set arbitrary tags to jobs and query the jobs using the API:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;user_id\u0026#34;: \u0026#34;12345\u0026#34; } } And then query the API to get only the results needed:\n$ curl http://localhost:8080/v1/jobs --data-urlencode \u0026quot;metadata[user_id]=12345\u0026quot;` "
},
{
	"uri": "/v2.0/usage/metatags/",
	"title": "Job metadata",
	"tags": [],
	"description": "",
	"content": "Job metadata Jobs can have an optional extra property field called metadata that allows to set arbitrary tags to jobs and query the jobs using the API:\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/bin/true\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;user_id\u0026#34;: \u0026#34;12345\u0026#34; } } And then query the API to get only the results needed:\n$ curl http://localhost:8080/v1/jobs --data-urlencode \u0026quot;metadata[user_id]=12345\u0026quot;` "
},
{
	"uri": "/usage/retries/",
	"title": "Job retries",
	"tags": [],
	"description": "",
	"content": "Jobs can be configured to retry in case of failure.\nConfiguration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n"
},
{
	"uri": "/v1.2/usage/retries/",
	"title": "Job retries",
	"tags": [],
	"description": "",
	"content": "Jobs can be configured to retry in case of failure.\nConfiguration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n"
},
{
	"uri": "/v2.0/usage/retries/",
	"title": "Job retries",
	"tags": [],
	"description": "",
	"content": "Jobs can be configured to retry in case of failure.\nConfiguration { \u0026#34;name\u0026#34;: \u0026#34;job1\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 10s\u0026#34;, \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;echo \\\u0026#34;Hello from parent\\\u0026#34;\u0026#34; }, \u0026#34;retries\u0026#34;: 5 } In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n"
},
{
	"uri": "/intro/license/",
	"title": "License",
	"tags": [],
	"description": "",
	"content": "Copyright (c) Victor Castell\nDkron is an Open Source project licensed under the terms of the LGPLv3 license. Please see http://www.gnu.org/licenses/lgpl-3.0.html for license text.\n"
},
{
	"uri": "/v1.2/intro/license/",
	"title": "License",
	"tags": [],
	"description": "",
	"content": "Copyright (c) Victor Castell\nDkron is an Open Source project licensed under the terms of the LGPLv3 license. Please see http://www.gnu.org/licenses/lgpl-3.0.html for license text.\n"
},
{
	"uri": "/v2.0/intro/license/",
	"title": "License",
	"tags": [],
	"description": "",
	"content": "Copyright (c) Victor Castell\nDkron is an Open Source project licensed under the terms of the LGPLv3 license. Please see http://www.gnu.org/licenses/lgpl-3.0.html for license text.\n"
},
{
	"uri": "/usage/processors/log/",
	"title": "Log Processor",
	"tags": [],
	"description": "",
	"content": "Log processor writes the execution output to stdout/stderr\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: \u0026#34;true\u0026#34; } } } "
},
{
	"uri": "/v1.2/usage/processors/log/",
	"title": "Log Processor",
	"tags": [],
	"description": "",
	"content": "Log processor writes the execution output to stdout/stderr\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: true } } } "
},
{
	"uri": "/v2.0/usage/processors/log/",
	"title": "Log Processor",
	"tags": [],
	"description": "",
	"content": "Log processor writes the execution output to stdout/stderr\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello log\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;log\u0026#34;: { \u0026#34;forward\u0026#34;: true } } } "
},
{
	"uri": "/usage/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": "Dkron has the ability to send metrics to Statsd for dashboards and historical reporting or provide prometheus format metrics via the api. It sends job processing metrics, golang, and serf metrics.\nConfiguration Statsd Add this in your yaml config file to enable statsd metrics.\nstatsd-addr: \u0026#34;localhost:8125\u0026#34; # Or for datadog statsd dog-statsd-addr: \u0026#34;localhost:8125\u0026#34; Prometheus Add this to your yaml config file to enable serving prometheus metrics at the endpoint /metrics\nenable-prometheus: true Metrics  dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query  "
},
{
	"uri": "/v1.2/usage/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": "Dkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too.\nConfiguration Add this in your yaml config file\ndog_statsd_addr: \u0026#34;localhost:8125\u0026#34; Metrics  dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query  "
},
{
	"uri": "/v2.0/usage/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": "Dkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too.\nConfiguration Add this in your yaml config file\ndog_statsd_addr: \u0026#34;localhost:8125\u0026#34; Metrics  dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.grpc.call_execution_done dkron.grpc.call_get_job dkron.grpc.execution_done dkron.grpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query  "
},
{
	"uri": "/usage/recovery/",
	"title": "Outage recovery",
	"tags": [],
	"description": "",
	"content": "Outage Recovery Don\u0026rsquo;t panic! This is a critical first step.\nDepending on your deployment configuration, it may take only a single server failure for cluster unavailability. Recovery requires an operator to intervene, but the process is straightforward.\nThis guide is for recovery from a Dkron outage due to a majority of server nodes in a datacenter being lost. If you are looking to add or remove servers, see the clustering guide.\n Failure of a Single Server Cluster If you had only a single server and it has failed, simply restart it. A single server configuration requires the -bootstrap-expect=1 flag. If the server cannot be recovered, you need to bring up a new server. See the clustering guide for more detail.\nIn the case of an unrecoverable server failure in a single server cluster, data loss is inevitable since data was not replicated to any other servers. This is why a single server deploy is never recommended.\nFailure of a Server in a Multi-Server Cluster If you think the failed server is recoverable, the easiest option is to bring it back online and have it rejoin the cluster with the same IP address, returning the cluster to a fully healthy state. Similarly, even if you need to rebuild a new Dkron server to replace the failed node, you may wish to do that immediately. Keep in mind that the rebuilt server needs to have the same IP address as the failed server. Again, once this server is online and has rejoined, the cluster will return to a fully healthy state.\nBoth of these strategies involve a potentially lengthy time to reboot or rebuild a failed server. If this is impractical or if building a new server with the same IP isn\u0026rsquo;t an option, you need to remove the failed server.\nBoth of these strategies involve a potentially lengthy time to reboot or rebuild a failed server. If this is impractical or if building a new server with the same IP isn\u0026rsquo;t an option, you need to remove the failed server. Usually, you can issue a dkron leave command to remove the failed server if it\u0026rsquo;s still a member of the cluster.\nIf dkron leave isn\u0026rsquo;t able to remove the server, you can use the dkron raft remove-peer command to remove the stale peer server on the fly with no downtime.\nYou can use the dkron raft list-peers command to inspect the Raft configuration:\n$ dkron raft list-peers Node ID Address State Voter dkron-server01.global 10.10.11.5:4647 10.10.11.5:4647 follower true dkron-server02.global 10.10.11.6:4647 10.10.11.6:4647 leader true dkron-server03.global 10.10.11.7:4647 10.10.11.7:4647 follower true Failure of Multiple Servers in a Multi-Server Cluster In the event that multiple servers are lost, causing a loss of quorum and a complete outage, partial recovery is possible using data on the remaining servers in the cluster. There may be data loss in this situation because multiple servers were lost, so information about what\u0026rsquo;s committed could be incomplete. The recovery process implicitly commits all outstanding Raft log entries, so it\u0026rsquo;s also possible to commit data that was uncommitted before the failure.\nSee the section below for details of the recovery procedure. You simply include just the remaining servers in the raft/peers.json recovery file. The cluster should be able to elect a leader once the remaining servers are all restarted with an identical raft/peers.json configuration.\nAny new servers you introduce later can be fresh with totally clean data directories.\nIn extreme cases, it should be possible to recover with just a single remaining server by starting that single server with itself as the only peer in the raft/peers.json recovery file.\nThe raft/peers.json recovery file is final, and a snapshot is taken after it is ingested, so you are guaranteed to start with your recovered configuration. This does implicitly commit all Raft log entries, so should only be used to recover from an outage, but it should allow recovery from any situation where there\u0026rsquo;s some cluster data available.\nManual Recovery Using peers.json To begin, stop all remaining servers. You can attempt a graceful leave, but it will not work in most cases. Do not worry if the leave exits with an error. The cluster is in an unhealthy state, so this is expected.\nThe peers.json file will be deleted after Dkron starts and ingests this file.\nUsing raft/peers.json for recovery can cause uncommitted Raft log entries to be implicitly committed, so this should only be used after an outage where no other option is available to recover a lost server. Make sure you don\u0026rsquo;t have any automated processes that will put the peers file in place on a periodic basis.\nThe next step is to go to the data-dir of each Dkron server. Inside that directory, there will be a raft/ sub-directory. We need to create a raft/peers.json file. It should look something like:\n[ { \u0026#34;id\u0026#34;: \u0026#34;node1\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;10.1.0.1:4647\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;node2\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;10.1.0.2:4647\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;node3\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;10.1.0.3:4647\u0026#34; } ] Simply create entries for all remaining servers. You must confirm that servers you do not include here have indeed failed and will not later rejoin the cluster. Ensure that this file is the same across all remaining server nodes.\nAt this point, you can restart all the remaining servers. In Dkron 0.5.5 and later you will see them ingest recovery file:\nRecovery log placeholder It should be noted that any existing member can be used to rejoin the cluster as the gossip protocol will take care of discovering the server nodes.\nAt this point, the cluster should be in an operable state again. One of the nodes should claim leadership and emit a log like:\n[INFO] Dkron: cluster leadership acquired\nYou can use the dkron raft list-peers command to inspect the Raft configuration:\n$ dkron raft list-peers Node ID Address State Voter node1 node1 10.10.11.5:4647 follower true node2 node2 10.10.11.6:4647 leader true node3 node3 10.10.11.7:4647 follower true   id (string: ) - Specifies the node ID of the server. This is the name of the node.\n  address (string: ) - Specifies the IP and port of the server in ip:port format. The port is the server\u0026rsquo;s gRPC port used for cluster communications, typically 6868.\n  "
},
{
	"uri": "/v2.0/usage/recovery/",
	"title": "Outage recovery",
	"tags": [],
	"description": "",
	"content": "Outage Recovery Don\u0026rsquo;t panic! This is a critical first step.\nDepending on your deployment configuration, it may take only a single server failure for cluster unavailability. Recovery requires an operator to intervene, but the process is straightforward.\nThis guide is for recovery from a Dkron outage due to a majority of server nodes in a datacenter being lost. If you are looking to add or remove servers, see the clustering guide.\n Failure of a Single Server Cluster If you had only a single server and it has failed, simply restart it. A single server configuration requires the -bootstrap-expect=1 flag. If the server cannot be recovered, you need to bring up a new server. See the clustering guide for more detail.\nIn the case of an unrecoverable server failure in a single server cluster, data loss is inevitable since data was not replicated to any other servers. This is why a single server deploy is never recommended.\nFailure of a Server in a Multi-Server Cluster If you think the failed server is recoverable, the easiest option is to bring it back online and have it rejoin the cluster with the same IP address, returning the cluster to a fully healthy state. Similarly, even if you need to rebuild a new Dkron server to replace the failed node, you may wish to do that immediately. Keep in mind that the rebuilt server needs to have the same IP address as the failed server. Again, once this server is online and has rejoined, the cluster will return to a fully healthy state.\nBoth of these strategies involve a potentially lengthy time to reboot or rebuild a failed server. If this is impractical or if building a new server with the same IP isn\u0026rsquo;t an option, you need to remove the failed server.\nBoth of these strategies involve a potentially lengthy time to reboot or rebuild a failed server. If this is impractical or if building a new server with the same IP isn\u0026rsquo;t an option, you need to remove the failed server. Usually, you can issue a dkron leave command to remove the failed server if it\u0026rsquo;s still a member of the cluster.\nIf dkron leave isn\u0026rsquo;t able to remove the server, you can use the dkron raft remove-peer command to remove the stale peer server on the fly with no downtime.\nYou can use the dkron raft list-peers command to inspect the Raft configuration:\n$ dkron raft list-peers Node ID Address State Voter dkron-server01.global 10.10.11.5:4647 10.10.11.5:4647 follower true dkron-server02.global 10.10.11.6:4647 10.10.11.6:4647 leader true dkron-server03.global 10.10.11.7:4647 10.10.11.7:4647 follower true Failure of Multiple Servers in a Multi-Server Cluster In the event that multiple servers are lost, causing a loss of quorum and a complete outage, partial recovery is possible using data on the remaining servers in the cluster. There may be data loss in this situation because multiple servers were lost, so information about what\u0026rsquo;s committed could be incomplete. The recovery process implicitly commits all outstanding Raft log entries, so it\u0026rsquo;s also possible to commit data that was uncommitted before the failure.\nSee the section below for details of the recovery procedure. You simply include just the remaining servers in the raft/peers.json recovery file. The cluster should be able to elect a leader once the remaining servers are all restarted with an identical raft/peers.json configuration.\nAny new servers you introduce later can be fresh with totally clean data directories.\nIn extreme cases, it should be possible to recover with just a single remaining server by starting that single server with itself as the only peer in the raft/peers.json recovery file.\nThe raft/peers.json recovery file is final, and a snapshot is taken after it is ingested, so you are guaranteed to start with your recovered configuration. This does implicitly commit all Raft log entries, so should only be used to recover from an outage, but it should allow recovery from any situation where there\u0026rsquo;s some cluster data available.\nManual Recovery Using peers.json To begin, stop all remaining servers. You can attempt a graceful leave, but it will not work in most cases. Do not worry if the leave exits with an error. The cluster is in an unhealthy state, so this is expected.\nThe peers.json file will be deleted after Dkron starts and ingests this file.\nUsing raft/peers.json for recovery can cause uncommitted Raft log entries to be implicitly committed, so this should only be used after an outage where no other option is available to recover a lost server. Make sure you don\u0026rsquo;t have any automated processes that will put the peers file in place on a periodic basis.\nThe next step is to go to the data-dir of each Dkron server. Inside that directory, there will be a raft/ sub-directory. We need to create a raft/peers.json file. It should look something like:\n[ { \u0026#34;id\u0026#34;: \u0026#34;node1\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;10.1.0.1:4647\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;node2\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;10.1.0.2:4647\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;node3\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;10.1.0.3:4647\u0026#34; } ] Simply create entries for all remaining servers. You must confirm that servers you do not include here have indeed failed and will not later rejoin the cluster. Ensure that this file is the same across all remaining server nodes.\nAt this point, you can restart all the remaining servers. In Dkron 0.5.5 and later you will see them ingest recovery file:\nRecovery log placeholder It should be noted that any existing member can be used to rejoin the cluster as the gossip protocol will take care of discovering the server nodes.\nAt this point, the cluster should be in an operable state again. One of the nodes should claim leadership and emit a log like:\n[INFO] Dkron: cluster leadership acquired\nYou can use the dkron raft list-peers command to inspect the Raft configuration:\n$ dkron raft list-peers Node ID Address State Voter node1 node1 10.10.11.5:4647 follower true node2 node2 10.10.11.6:4647 leader true node3 node3 10.10.11.7:4647 follower true   id (string: ) - Specifies the node ID of the server. This is the name of the node.\n  address (string: ) - Specifies the IP and port of the server in ip:port format. The port is the server\u0026rsquo;s gRPC port used for cluster communications, typically 6868.\n  "
},
{
	"uri": "/usage/plugins/",
	"title": "Plugins",
	"tags": [],
	"description": "",
	"content": "Intro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs.\nThis page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin.\nHow it Works Dkron execution execution processors are provided via plugins. Each plugin exposes functionality for modifying the execution. Plugins are executed as a separate process and communicate with the main Dkron binary over an RPC interface.\nThe code within the binaries must adhere to certain interfaces. The network communication and RPC is handled automatically by higher-level libraries. The exact interface to implement is documented in its respective documentation section.\nInstalling a Plugin Dkron searches for plugins at startup, to install a plugin just drop the binary in one of the following locations:\n /etc/dkron/plugins Dkron executable directory   Developing plugins \n "
},
{
	"uri": "/v1.2/usage/plugins/",
	"title": "Plugins",
	"tags": [],
	"description": "",
	"content": "Intro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs.\nThis page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin.\nHow it Works Dkron execution execution processors are provided via plugins. Each plugin exposes functionality for modifying the execution. Plugins are executed as a separate process and communicate with the main Dkron binary over an RPC interface.\nThe code within the binaries must adhere to certain interfaces. The network communication and RPC is handled automatically by higher-level libraries. The exact interface to implement is documented in its respective documentation section.\nInstalling a Plugin Dkron searches for plugins at startup, to install a plugin just drop the binary in one of the following locations:\n /etc/dkron/plugins Dkron executable directory   Developing plugins \n "
},
{
	"uri": "/v2.0/usage/plugins/",
	"title": "Plugins",
	"tags": [],
	"description": "",
	"content": "Intro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs.\nThis page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin.\nHow it Works Dkron execution execution processors are provided via plugins. Each plugin exposes functionality for modifying the execution. Plugins are executed as a separate process and communicate with the main Dkron binary over an RPC interface.\nThe code within the binaries must adhere to certain interfaces. The network communication and RPC is handled automatically by higher-level libraries. The exact interface to implement is documented in its respective documentation section.\nInstalling a Plugin Dkron searches for plugins at startup, to install a plugin just drop the binary in one of the following locations:\n /etc/dkron/plugins Dkron executable directory   Developing plugins \n "
},
{
	"uri": "/pro/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": " Elasticsearch processor\nThe Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node. The output logs of the job execution will be stored in the indicated ES instace. Configuration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } }   Email processor\nThe Email processor provides flexibility to job email notifications. Configuration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers. Example: provider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.\n  Slack processor\nThe Slack processor provides slack notifications with multiple configurations and rich format. Configuration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams. Example: team1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: \u0026#34;true\u0026#34; } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n  "
},
{
	"uri": "/v1.2/pro/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": " Elasticsearch processor\nThe Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node. The output logs of the job execution will be stored in the indicated ES instace. Configuration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } }   Email processor\nThe Email processor provides flexibility to job email notifications. Configuration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers. Example: provider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.\n  Slack processor\nThe Slack processor provides slack notifications with multiple configurations and rich format. Configuration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams. Example: team1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: true } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n  "
},
{
	"uri": "/v2.0/pro/processors/",
	"title": "Processors",
	"tags": [],
	"description": "",
	"content": " Elasticsearch processor\nThe Elasticsearch processor can fordward execution logs to an ES cluster. It need an already available Elasticsearch installation that is visible in the same network of the target node. The output logs of the job execution will be stored in the indicated ES instace. Configuration { \u0026#34;processors\u0026#34;: { \u0026#34;elasticsearch\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;http://localhost:9200\u0026#34;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026#34;index\u0026#34;: \u0026#34;dkron_logs\u0026#34;, //desired index name (default: dkron_logs) \u0026#34;forward\u0026#34;: \u0026#34;false\u0026#34; //forward logs to the next processor (default: false) } } }   Email processor\nThe Email processor provides flexibility to job email notifications. Configuration of the email processor is stored in a file named dkron-processor-email.yml in the same locations as dkron.yml, and should include a list of providers, it can include any number of providers. Example: provider1: host: smtp.myprovider.com port: 25 username: myusername password: mypassword from: cron@mycompany.com subjectPrefix: \u0026#39;[Staging] \u0026#39; Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;email\u0026#34;: { \u0026#34;provider\u0026#34;: \u0026#34;provider1\u0026#34;, \u0026#34;emails\u0026#34;: \u0026#34;team@mycompany.\n  Slack processor\nThe Slack processor provides slack notifications with multiple configurations and rich format. Configuration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams. Example: team1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options: Example: { \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: \u0026#34;true\u0026#34; } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n  "
},
{
	"uri": "/usage/executors/shell/",
	"title": "Shell Executor",
	"tags": [],
	"description": "",
	"content": "Shell executor runs a system command\nConfiguration Params\nshell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } } "
},
{
	"uri": "/v1.2/usage/executors/shell/",
	"title": "Shell Executor",
	"tags": [],
	"description": "",
	"content": "Shell executor runs a system command\nConfiguration Params\nshell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } } "
},
{
	"uri": "/v2.0/usage/executors/shell/",
	"title": "Shell Executor",
	"tags": [],
	"description": "",
	"content": "Shell executor runs a system command\nConfiguration Params\nshell: Run this command using a shell environment command: The command to run env: Env vars separated by comma cwd: Chdir before command run Example\n{ \u0026#34;executor\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;executor_config\u0026#34;: { \u0026#34;shell\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;my_command\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;ENV_VAR=va1,ANOTHER_ENV_VAR=var2\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;/app\u0026#34; } } "
},
{
	"uri": "/pro/processors/slack/",
	"title": "Slack processor",
	"tags": [],
	"description": "",
	"content": "The Slack processor provides slack notifications with multiple configurations and rich format.\nConfiguration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams.\nExample:\nteam1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: \u0026#34;true\u0026#34; } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/v1.2/pro/processors/slack/",
	"title": "Slack processor",
	"tags": [],
	"description": "",
	"content": "The Slack processor provides slack notifications with multiple configurations and rich format.\nConfiguration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams.\nExample:\nteam1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: true } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/v2.0/pro/processors/slack/",
	"title": "Slack processor",
	"tags": [],
	"description": "",
	"content": "The Slack processor provides slack notifications with multiple configurations and rich format.\nConfiguration of the slack processor is stored in a file named dkron-processor-slack.yml in the same locations as dkron.yml, and should include a list of teams, it can include any number of teams.\nExample:\nteam1: webhook_url: https://hooks.slack.com/services/XXXXXXXXXXXXXXXXXXX bot_name: Dkron Production Then configure each job with the following options:\nExample:\n{ \u0026#34;processors\u0026#34;: { \u0026#34;slack\u0026#34;: { \u0026#34;team\u0026#34;: \u0026#34;team1\u0026#34;, \u0026#34;channel\u0026#34;: \u0026#34;#cron-production\u0026#34;, \u0026#34;onSuccess\u0026#34;: \u0026#34;true\u0026#34; } } } By default the slack procesor doesn\u0026rsquo;t send notifications on job success, the onSuccess parameter, enables it, like in the previous example.\n"
},
{
	"uri": "/usage/processors/syslog/",
	"title": "Syslog Processor",
	"tags": [],
	"description": "",
	"content": "Syslog processor writes the execution output to the system syslog daemon\nNote: Only work on linux systems\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: \u0026#34;true\u0026#34; } } } "
},
{
	"uri": "/v1.2/usage/processors/syslog/",
	"title": "Syslog Processor",
	"tags": [],
	"description": "",
	"content": "Syslog processor writes the execution output to the system syslog daemon\nNote: Only work on linux systems\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: true } } } "
},
{
	"uri": "/v2.0/usage/processors/syslog/",
	"title": "Syslog Processor",
	"tags": [],
	"description": "",
	"content": "Syslog processor writes the execution output to the system syslog daemon\nNote: Only work on linux systems\nConfiguration Parameters\nforward: Forward the output to the next processor\nExample\n{ \u0026#34;name\u0026#34;: \u0026#34;job_name\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;echo \u0026#39;Hello syslog\u0026#39;\u0026#34;, \u0026#34;schedule\u0026#34;: \u0026#34;@every 2m\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;web\u0026#34; }, \u0026#34;processors\u0026#34;: { \u0026#34;syslog\u0026#34;: { \u0026#34;forward\u0026#34;: true } } } "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/upgrading/from_v1_to_v2/",
	"title": "Upgrade from v1 to v2",
	"tags": [],
	"description": "",
	"content": "Dkron v2 brings lots of changes to the previous version. To successfully upgrade from v1 to v2 you need to take care of certain steps.\nStorage Dkron v2 brings native storage, no external storage engine is needed. This change can be shocking for existing users and should be carefully planned to consider Dkron as a stateful service in contrast of a stateless service as in v1.\nYou must plan a backup strategy for the data directories, you can configure it using the --data-dir parameter, by default ./dkron.data.\nThis will ensure that you can recover cluster data in case of an unexpected failure.\nMigrating Jobs To migrate jobs from v1 to v2, export jobs from the v1 cluster and import them into v2.\nA basic script to do that can be found here\nYou can take the opportunity to update your job definitions as explained in the following section:\nChange job name In v2 dkron doesn\u0026rsquo;t accept jobs with invalid naming, adapt your scripts or api calls if necessary to set the job name with valid characters.\nChanging tags and metadata Tags behave different in dkron 2. There are several dkron tags that changed names and have become reserved. The reserved tags are:\n dc region role version server bootstrap expect rpc_addr port  You can not set these tags with the tags param. Tags region and dc can be set using the region and datacenter params, respectively.\nIn Dkron 2, the job filtering API now filters on the metadata instead of the tags field. Jobs have a new param metadata that can be used to set any data to classify jobs. These can then be used to filter results returned by the API.\n"
},
{
	"uri": "/v2.0/upgrading/from_v1_to_v2/",
	"title": "Upgrade from v1 to v2",
	"tags": [],
	"description": "",
	"content": "Dkron v2 brings lots of changes to the previous version. To successfully upgrade from v1 to v2 you need to take care of certain steps.\nStorage Dkron v2 brings native storage, no external storage engine is needed. This change can be shocking for existing users and should be carefully planned to consider Dkron as a stateful service in contrast of a stateless service as in v1.\nYou must plan a backup strategy for the data directories, you can configure it using the --data-dir parameter, by default ./dkron.data.\nThis will ensure that you can recover cluster data in case of an unexpected failure.\nMigrating Jobs To migrate jobs from v1 to v2, export jobs from the v1 cluster and import them into v2.\nA basic script to do that can be found here\nYou can take the opportunity to update your job definitions as explained in the following section:\nChange job name In v2 dkron doesn\u0026rsquo;t accept jobs with invalid naming, adapt your scripts or api calls if necessary to set the job name with valid characters.\nChanging tags and metadata Tags behave different in dkron 2. There are several dkron tags that changed names and have become reserved. The reserved tags are:\n dc region role version server bootstrap expect rpc_addr port  You can not set these tags with the tags param. Tags region and dc can be set using the region and datacenter params, respectively.\nIn Dkron 2, the job filtering API now filters on the metadata instead of the tags field. Jobs have a new param metadata that can be used to set any data to classify jobs. These can then be used to filter results returned by the API.\n"
},
{
	"uri": "/upgrading/from_v2_0_to_v2_2/",
	"title": "Upgrade from v2.0.x to v2.2.x",
	"tags": [],
	"description": "",
	"content": "Migrating Jobs To migrate jobs from v2.0.x to v2.2.x, export jobs from the v2.0.x cluster and import them into v2.2.x\nRefer to the backup\u0026amp;restore upgrade guide\n"
},
{
	"uri": "/usage/upgrade/",
	"title": "Upgrade methods",
	"tags": [],
	"description": "",
	"content": "Use one of the following methods (depending on the changes) to upgrade a cluster to a newer version.\nRolling upgrade Use the following procedure to rotate all cluster nodes, one server at a time:\n Add a new servers to the cluster with a configuration that joins them to the existing cluter. Stop dkron service in one of the old servers, if it was the leader allow a new leader to be ellected, note that it is better to remove the current leader at the end, to ensure a leader is elected between the new nodes. Use dkron raft list-peers to list current cluster nodes Use dkron raft remove-peer to forcefully remove the old server Repeat steps util all old cluster nodes has been rotated  Backup \u0026amp; Restore Use the /restore API endpoint to restore a previously exported jobs file\ncurl localhost:8080/v1/jobs \u0026gt; backup.json curl localhost:8080/v1/restore --form 'file=@backup.json' This will restore all jobs and counters as they were in the export file.\n"
},
{
	"uri": "/upgrading/",
	"title": "Upgradings",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/usage/ecs/",
	"title": "Use with AWS ECS",
	"tags": [],
	"description": "",
	"content": " Dkron Pro comes with a native ECS executor out of the box.\n Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed.\nInstall the following snippet in the node that will run the call to ECS\n Prerequisites The node that will run the call to ECS will need to have installed\n AWS cli jq  Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n"
},
{
	"uri": "/v1.2/usage/ecs/",
	"title": "Use with AWS ECS",
	"tags": [],
	"description": "",
	"content": " Dkron Pro comes with a native ECS executor out of the box.\n Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed.\nInstall the following snippet in the node that will run the call to ECS\n Prerequisites The node that will run the call to ECS will need to have installed\n AWS cli jq  Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n"
},
{
	"uri": "/v2.0/usage/ecs/",
	"title": "Use with AWS ECS",
	"tags": [],
	"description": "",
	"content": " Dkron Pro comes with a native ECS executor out of the box.\n Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed.\nInstall the following snippet in the node that will run the call to ECS\n Prerequisites The node that will run the call to ECS will need to have installed\n AWS cli jq  Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n"
}]